<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>libreliu&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="libreliu&#39;s blog">
<meta property="og:url" content="https://blog.libreliu.info/">
<meta property="og:site_name" content="libreliu&#39;s blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Libre Liu">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="/css/images/logo.png">
  
  <link href="/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  
<link rel="stylesheet" href="/css/style.css">

  

<meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="libreliu's blog" type="application/atom+xml">
</head>

<body>
  <div id="container">
    <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/paper-summary">Paper Reading</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://blog.libreliu.info"></form>
        </div>
      </nav>
    </div>
  </div>
</header>

    <br>
    <section id="main" class="outer">
      <article id="paper-reading-paper-reading/learning-from-program-traces" class="article article-type-paper-reading" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/paper-reading/learning-from-program-traces/"><strong>论文阅读 | Learning from Shader Program Traces</strong></a>
      <small class=article-date-index>&nbsp; 2023-01-03</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/paper-reading/learning-from-program-traces/" class="article-date">
  <time datetime="2023-01-02T16:00:00.000Z" itemprop="datePublished">2023-01-03</time>
</a>-->
      <!--
-->
      <!--
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul>
<li>Program trace<ul>
<li>In software engineering, a trace refers to the record of all states that a program visits during its execution, including all instructions and data.</li>
<li>本文提到的 Shader program trace，只包括中间结果 (<strong>data</strong>)，而不包括程序序列 (<strong>instruction</strong>)。</li>
</ul>
</li>
</ul>
<p>Since the fragment shader program operates independently per pixel, we can consider the full program trace as a vector of values computed at each pixel – a generalization from simple RGB.</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><ul>
<li>输入是用（嵌入到 Python 的） DSL 写的 fragment procedural shader program，翻译成 Tensorflow 程序<ul>
<li>可以同时输出渲染好的图片和生成的 program trace</li>
<li>分支展开、循环 unroll</li>
<li>These policies permit us to express the trace of any shader as a fixed-length vector of the computed scalar values, regardless of the pixel location</li>
</ul>
</li>
</ul>
<h3 id="输入特征化简"><a href="#输入特征化简" class="headerlink" title="输入特征化简"></a>输入特征化简</h3><ul>
<li>编译器优化<ul>
<li>忽略常量值、计算图上重复的节点，因为其在不同 pixel 位置的运行结果应该高度统一</li>
</ul>
</li>
<li>不生成内建函数的 trace</li>
<li>检测并筛除迭代改进模式的循环中的中间 trace 结果<ul>
<li>比如，raymarching 找 closest intersection 的迭代</li>
</ul>
</li>
<li>均匀的特征下采样<ul>
<li>The most straightforward strategy is to subsample the vector by some factor n, retaining only every nth trace feature as ordered in a depth first traversal of the compute graph</li>
</ul>
</li>
<li>其它采样方案 (都不太好用)<ul>
<li>clustering</li>
<li>loop subsampling</li>
<li>first or last</li>
<li>mean and variance</li>
</ul>
</li>
</ul>
<p>We <strong>first apply compiler optimizations</strong>, then <strong>subsample the features with a subsampling rate that makes the trace length be most similar to a fixed target length</strong>.</p>
<p>For all experiments, we target a length of 200, except where specifically noted such as in the simulation example. </p>
<p>After compiling and executing the shader, we have <strong>for every pixel: a vector of dimension N</strong>: the number of recorded intermediate values in the trace</p>
<h3 id="特征白化"><a href="#特征白化" class="headerlink" title="特征白化"></a>特征白化</h3><p>主要是为了解决 shader trace 里面的异常值，防止干扰训练和推理。用的是 Scaling + clamping。</p>
<ul>
<li>Check if the distribution merits clamping<ul>
<li>If N &lt;&#x3D; 10, no need to clamp</li>
<li>Else, do clamp<ul>
<li>Discard NaN, Inf, -Inf</li>
<li>let $P_0$ &#x3D; Lowest p’th percentile, $P_1$ &#x3D; highest p’th percentile, superparam $ \gamma $</li>
<li>Clamp to $ [P_0 − \gamma(P_1− P_0), P_1 + \gamma(P_1 − P_0)] $</li>
</ul>
</li>
<li>Do rescale<ul>
<li>for each intermediate feature, rescale the clamped values to the fixed range $ [-1,1] $</li>
<li>Record the bias and scale used (in rescaling)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The scale and bias is recorded and used in both training and testing, but the values will be clamped to range<br>[-2, 2] to allow data extrapolation.</p>
<blockquote>
<p>感觉有点乱…</p>
</blockquote>
<h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><h4 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h4><ul>
<li>1x1 Conv + Feature Reduction (N &#x3D; 200 -&gt; K &#x3D; 48) </li>
<li>1x1 Conv * 3</li>
<li>Dilated Convolution (1, 2, 4, 8, 1)</li>
<li>1x1 Conv * 3 </li>
<li>1x1 Conv + Feature Reduction (K &#x3D; 48 -&gt; 3, that is, RGB color output)</li>
</ul>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>$ L_b = L_c + \alpha L_p $</p>
<ul>
<li>$ L_c $ 是 RGB 图像上的标准 $ L_2 $ loss</li>
<li>$ L_p $ 是 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1801.03924">The Unreasonable Effectiveness of Deep Features as a Perceptual Metric</a> 这篇文章中给出的损失函数度量 LPIPS<ul>
<li>大概就是，做了一个图像相似数据集，弄了很多 distortions 和 CNN 常见任务输出的图片，做 2AFC 和 JND，随后学习这个 metric</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/162070277">深度特征度量图像相似度的有效性——LPIPS</a> 这篇知乎文章比较不错</li>
</ul>
</li>
</ul>
<p>下面还有个 Appendix D，里面有实验的 GAN 的 loss</p>
<h4 id="训练策略"><a href="#训练策略" class="headerlink" title="训练策略"></a>训练策略</h4><h2 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h2><p>和一个 Baseline 方法 RGBx 对比，这个 Baseline 用的手挑特征 normal, depth, diffuse, specular color (<em>where applicable</em>) 来作为输入进行学习。</p>
<h3 id="Denoising-fragment-shaders"><a href="#Denoising-fragment-shaders" class="headerlink" title="Denoising fragment shaders"></a>Denoising fragment shaders</h3><p>目标是用 1spp 图像来学习 1000spp 的 reference image。</p>
<h3 id="Reconstructing-simplified-shaders"><a href="#Reconstructing-simplified-shaders" class="headerlink" title="Reconstructing simplified shaders"></a>Reconstructing simplified shaders</h3><p>这个任务是，从简化后的 Shader 的运行结果中，重建原来 Shader 的运行结果。</p>
<p>简化 Shader 采用的是 Loop perforation 和 Genetic Programming Simplification。</p>
<p>用两个 Conditional GAN，分别称为 Spatial GAN 和 Temporal GAN，一个用来从 1spp 的图 $ c_x $ 生成 Ground Truth (原来的 Shader 运行结果) $ c_y $，另一个用来从前面三帧的 1spp 输出 + 前面两帧的 Spatial GAN 的生成器的输出来生成下一帧，也就是用序列 $ \tilde {c_x} $ 生成序列 $ \tilde {c_y} $。</p>
<blockquote>
<p>GAN related:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/301309418">四天搞懂生成对抗网络（一）——通俗理解经典GAN</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/302720602">四天搞懂生成对抗网络（二）——风格迁移的“精神始祖”Conditional GAN</a></li>
</ul>
</blockquote>
<h3 id="Postprocessing-filters"><a href="#Postprocessing-filters" class="headerlink" title="Postprocessing filters"></a>Postprocessing filters</h3><p>学习一些后处理效果的 Shader，如 edge-aware sharpening filter 和 defocus blur 效果。</p>
<h3 id="Learning-to-approximate-simulation"><a href="#Learning-to-approximate-simulation" class="headerlink" title="Learning to approximate simulation"></a>Learning to approximate simulation</h3><p>学习一些进行模拟的 Shader 将来的运行结果。</p>
<h2 id="Trace-有效性分析"><a href="#Trace-有效性分析" class="headerlink" title="Trace 有效性分析"></a>Trace 有效性分析</h2><p>这里主要做了两件事：</p>
<ol>
<li>哪些 Input feature 比较重要？<ul>
<li>这里作者采用求 Loss 关于 input trace feature 的一阶导数来评价重要性</li>
</ul>
</li>
<li>挑一个 Subset 来做训练？<ul>
<li>给定 m 个 feature 的训练 budget，如果要评价任意的 subset，即从 N 个里面抽 m 个来做训练的话，开销太大<ul>
<li>Oracle: 按 1 中所述重要性评分的前 m 个 input trace feature</li>
<li>Opponent: 按 1 中所述重要性评分的后 m 个 input trace feature</li>
<li>Uniform: 随便挑 m 个</li>
</ul>
</li>
<li>发现 Oracle &gt; Opponent &gt; Uniform</li>
</ul>
</li>
<li>多个 Shader 一起学习<ul>
<li>多个 Shader 一起学习降噪任务，感觉就像训练一个真·denoiser</li>
</ul>
</li>
</ol>

      
    </div>
	
    <!--
	
    -->
    <!--
    
    -->
  </div>
  
</article>



    
      <article id="post-example-vulkan-app-flow" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/example-vulkan-app-flow/"><strong>一个示例 Vulkan 程序的全流程记录</strong></a>
      <small class=article-date-index>&nbsp; 2022-12-29</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/example-vulkan-app-flow/" class="article-date">
  <time datetime="2022-12-28T16:00:00.000Z" itemprop="datePublished">2022-12-29</time>
</a>-->
      <!--
-->
      <!--
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><blockquote>
<p>一些有用的链接：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.khronos.org/blog/understanding-vulkan-synchronization">Khronos Blog - Understanding Vulkan Synchronization</a></li>
<li><a target="_blank" rel="noopener" href="https://themaister.net/blog/2019/08/14/yet-another-blog-explaining-vulkan-synchronization/">Yet another blog explaining Vulkan synchronization - Maister’s Graphics Adventures</a></li>
</ul>
</blockquote>
<p>本文主要分析 <a target="_blank" rel="noopener" href="https://github.com/glfw/glfw">glfw</a> 库的 <a target="_blank" rel="noopener" href="https://github.com/glfw/glfw/blob/57cbded0760a50b9039ee0cb3f3c14f60145567c/tests/triangle-vulkan.c">tests&#x2F;triangle-vulkan.c</a> 文件。</p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><ul>
<li>demo_init<ul>
<li>demo_init_connection<ul>
<li>glfwSerErrorCallback</li>
<li>gladLoadVulkanUserPtr: 设定 glad 使用 glfwGetInstanceProcAddress 来装载所有的 Vulkan 函数指针地址</li>
</ul>
</li>
<li>demo_init_vk<ul>
<li>启用验证层:<ul>
<li>vkEnumerateInstanceLayerProperties</li>
<li>demo_check_layers: 检查需要的验证层集合是否存在</li>
</ul>
</li>
<li>glfwGetRequiredInstanceExtensions: 获得需要的平台 Surface 扩展</li>
<li>准备启用的 Instance 扩展列表<ul>
<li>VK_EXT_debug_report</li>
<li>VK_KHR_portability_enumeration</li>
</ul>
</li>
<li>vkCreateInstance</li>
<li>vkEnumeratePhysicalDevices</li>
<li>检查设备是否支持 VK_KHR_swapchain<ul>
<li>vkEnumerateDeviceExtensionProperties</li>
</ul>
</li>
<li>vkCreateDebugReportCallbackEXT</li>
<li>vkGetPhysicalDeviceProperties</li>
<li>vkGetPhysicalDeviceQueueFamilyProperties</li>
<li>vkGetPhysicalDeviceFeatures</li>
</ul>
</li>
</ul>
</li>
<li>demo_create_window<ul>
<li>glfwWindowHint</li>
<li>glfwCreateWindow</li>
<li>glfwSetWindowUserPointer</li>
<li>glfwSetWindowRefreshCallback</li>
<li>glfwSetFramebufferSizeCallback</li>
<li>glfwSetKeyCallback</li>
</ul>
</li>
<li>demo_init_vk_swapchain<ul>
<li>glfwCreateWindowSurface<ul>
<li>内部调用 vkCreateWin32SurfaceKHR</li>
</ul>
</li>
<li>查找支持 Present 和 Graphics 的 Queue，需要是同一个 Queue<ul>
<li>vkGetPhysicalDeviceSurfaceSupportKHR</li>
<li><code>queueFlags &amp; VK_QUEUE_GRAPHICS_BIT</code></li>
</ul>
</li>
<li>vkGetDeviceQueue</li>
<li>选择一个最优的 Surface format<ul>
<li>vkGetPhysicalDeviceSurfaceFormatsKHR</li>
</ul>
</li>
<li>vkGetPhysicalDeviceMemoryProperties</li>
</ul>
</li>
<li>demo_prepare<ul>
<li>创建 Command Pool<ul>
<li>vkCreateCommandPool</li>
</ul>
</li>
<li>分配一个 Command Buffer<ul>
<li>vkAllocateCommandBuffers<ul>
<li>VkCommandBufferAllocateInfo:<ul>
<li><code>.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY</code></li>
<li><code>.commandBufferCount = 1</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>demo_prepare_buffers<ul>
<li>检查 Surface Capabilities 和 Present Modes<ul>
<li>vkGetPhysicalDeviceSurfaceCapabilitiesKHR</li>
<li>vkGetPhysicalDeviceSurfacePresentModesKHR</li>
</ul>
</li>
<li>创建交换链<ul>
<li>计算 Swapchain Image Extent</li>
<li><code>.preTransform</code> 使用 <code>VK_SURFACE_TRANSFORM_IDENTITY_BIT_KHR</code>，如果没有则使用当前 Surface Transform</li>
<li><code>.minImageCount</code> 使用 Surface Capabilities 的 minImageCount</li>
<li><code>.presentMode</code> 选择 <code>VK_PRESENT_MODE_FIFO_KHR</code></li>
<li>vkCreateSwapchainKHR</li>
<li>如果有老的交换链： vkDestroySwapchainKHR</li>
<li>vkGetSwapchainImagesKHR 拿到 VkImage 格式的交换链图像</li>
<li>为每个交换链图像调用 vkCreateImageView 创建 Color Attachment View<blockquote>
<p>Componet Swizzle: TODO check spec</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
<li>demo_prepare_depth<ul>
<li>vkCreateImage 创建 depth image<ul>
<li><code>.arrayLayers</code> 可以指定 texture array 的 dimension</li>
</ul>
</li>
<li>vkGetImageMemoryRequirements 获得 image 的内存要求</li>
<li>选择内存大小和内存类型<ul>
<li>memory_type_from_properties : todo check this</li>
</ul>
</li>
<li>vkAllocateMemory 分配 image 所需内存，返回 VkDeviceMemory</li>
<li>vkBindImageMemory 将分配的 VkDeviceMemory 绑定到 VkImage</li>
<li>demo_set_image_layout<ul>
<li>如果 <code>demo-&gt;setup_cmd</code> 为空，则<ul>
<li>调用 vkAllocateCommandBuffers 从 <code>demo-&gt;cmd_pool</code> 中分配 <code>VK_COMMAND_BUFFER_LEVEL_PRIMARY</code> 的 Buffer</li>
<li>vkBeginCommandBuffer</li>
</ul>
</li>
<li>准备 Image Memory Barrier<ul>
<li>VkImageMemoryBarrier<ul>
<li><code>.srcAccessMask = 0</code><ul>
<li>不需要给 src stage 的任何读&#x2F;写操作 made coherent</li>
</ul>
</li>
<li><code>.dstAccessMask</code>:<ul>
<li>对于 <code>VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL</code>，设置为 <code>VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT</code></li>
</ul>
</li>
<li><code>.oldLayout = VK_IMAGE_LAYOUT_UNDEFINED</code>，也就是垃圾数据</li>
<li><code>.newLayout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL</code></li>
</ul>
</li>
</ul>
</li>
<li>录制 Pipeline Barrier<ul>
<li>vkCmdPipelineBarrier<ul>
<li><code>srcStageMask = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT</code>，也就是 wait for nothing</li>
<li><code>dstStageMask = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT</code>，也就是任何下面的指令在开始前都需要等待 Barrier 执行完</li>
<li>同时传入前面的 Image Mmeory Barrier</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>vkCreateImageView 创建深度缓冲对应图像的 ImageView</li>
</ul>
</li>
<li>demo_prepare_textures<ul>
<li>vkGetPhysicalDeviceFormatProperties 获得 <code>VK_FORMAT_B8G8R8A8_UNORM</code> 的 VkFormatProperties</li>
<li>对于每张 texture<blockquote>
<p>用 <code>texture_object</code> 来管理每个 texture</p>
<ul>
<li>VkSampler sampler</li>
<li>VkImage iamge;</li>
<li>VkImageLayout imageLayout;</li>
<li>VkDeviceMemory mem;</li>
<li>VkImageView view;</li>
<li>int32_t tex_width, tex_height;</li>
</ul>
</blockquote>
<ul>
<li>如果 sampler 支持（对此种 format 的）线性分块 <code>(props.linearTilingFeatures &amp; VK_FORMAT_FEATURE_SAMPLED_IMAGE_BIT)</code><ul>
<li>demo_prepare_texture_image with required_props &#x3D; <code>VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT</code><ul>
<li>vkCreateImage</li>
<li>vkGetImageMemoryRequirements</li>
<li>memory_type_from_properties<ul>
<li>对设备支持的每种内存类型，枚举其是否符合前面 <code>required_props</code> 的要求</li>
</ul>
</li>
<li>vkAllocateMemory</li>
<li>vkBindImageMemory</li>
<li>如果 memory type 有性质 <code>VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT</code><ul>
<li>vkGetImageSubresourceLayout</li>
<li>vkMapMemory: 映射到地址空间</li>
<li>填充之</li>
<li>vkUnmapMemory</li>
</ul>
</li>
<li>设置 image layout (前面分析过)<ul>
<li><code>VK_IMAGE_LAYOUT_PREINITIALIZED</code> -&gt; <code>VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL</code></li>
<li>demo_set_image_layout</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>如果 sampler 不支持对此种 format 的线性分块，但支持 optimal 分块 <code>(props.optimalTilingFeatures &amp;  VK_FORMAT_FEATURE_SAMPLED_IMAGE_BIT)</code><ul>
<li>分别准备 host coherent 和 host visible 的 staging texture 和 GPU device local 的 texture<ul>
<li>demo_prepare_texture_image * 2<ul>
<li>这里 device local 的显然没能力初始化</li>
</ul>
</li>
<li>注意 memory props</li>
</ul>
</li>
<li>改 layout 以便使用 transfer 命令<ul>
<li>staging texture: VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL</li>
<li>device local texture: VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL</li>
</ul>
</li>
<li>vkCmdCopyImage</li>
<li>将 device local texture 的 layout 改回来<ul>
<li>demo_set_image_layout</li>
</ul>
</li>
<li>demo_flush_init_cmd: 同步方式 flush setup cmd<ul>
<li>vkEndCommandBuffer</li>
<li>vkQueueSubmit<ul>
<li>no wait &#x2F; signal semaphores</li>
</ul>
</li>
<li>vkQueueWaitIdle</li>
<li>vkFreeCommandBuffers</li>
<li><code>demo-&gt;setup_cmd = VK_NULL_HANDLE</code></li>
</ul>
</li>
<li>demo_destroy_texture_image 销毁 staging texture</li>
</ul>
</li>
<li>创建对应的 sampler 和 Image View<ul>
<li>vkCreateSampler</li>
<li>vkCreateImageView</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>demo_prepare_vertices<blockquote>
<p>这里直接用了 Host visible &amp; Host coherent 的 memory 作为 vertex buffer<br>而不是 Device local 的，然后单开 staging buffer 做拷贝.</p>
<p>应该是偷懒了.jpg</p>
</blockquote>
<ul>
<li>vkCreateBuffer<ul>
<li>with <code>.usage = VK_BUFFER_USAGE_VERTEX_BUFFER_BIT</code></li>
</ul>
</li>
<li>vkGetBufferMemoryRequirements</li>
<li>memory_type_from_properties</li>
<li>vkAllocateMemory</li>
<li>vkMapMemory</li>
<li>vkUnmapMemory</li>
<li>vkBindBufferMemory</li>
<li>配置一些结构体<ul>
<li>VkPipelineVertexInputStateCreateInfo<ul>
<li>VkVertexInputBindingDescription</li>
<li>VkVertexInputAttributeDescription</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>demo_prepare_descriptor_layout<ul>
<li>vkCreateDescriptorSetLayout<ul>
<li>VkDescriptorSetLayoutCreateInfo</li>
<li><code>.pBindings = &amp;layout_binding</code><ul>
<li>layout_binding: 设置每个 binding 的位置都放什么 - 可以为数组<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">const VkDescriptorSetLayoutBinding layout_binding = &#123;</span><br><span class="line">  .binding = 0,</span><br><span class="line">  .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,</span><br><span class="line">  .descriptorCount = DEMO_TEXTURE_COUNT,</span><br><span class="line">  .stageFlags = VK_SHADER_STAGE_FRAGMENT_BIT,</span><br><span class="line">  .pImmutableSamplers = NULL,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
See also: <a target="_blank" rel="noopener" href="https://vkguide.dev/docs/chapter-4/descriptors/">https://vkguide.dev/docs/chapter-4/descriptors/</a></li>
</ul>
</li>
</ul>
</li>
<li>vkCreatePipelineLayout<ul>
<li>VkPipelineLayoutCreateInfo: <code>demo-&gt;pipeline_layout</code><ul>
<li>指定了到 Descriptor Set Layouts 的数量和数组指针</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>demo_prepare_render_pass<ul>
<li>vkCreateRenderPass<ul>
<li>VkRenderPassCreateInfo<ul>
<li><code>.pAttachments</code>: VkAttachmentDescription<ul>
<li><code>[0]</code>: Color Attachment<ul>
<li><code>.samples = VK_SAMPLE_COUNT_1_BIT</code> 图像的 sample 数</li>
<li><code>.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR</code> color &amp; depth 内容在 subpass 开始时如何处理</li>
<li><code>.storeOp = VK_ATTACHMENT_STORE_OP_STORE</code> color &amp; depth 内容在 subpass 结束后如何处理</li>
<li><code>.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE</code> stencil 内容在 subpass 开始时如何处理</li>
<li><code>.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE</code> stencil 内容在 subpass 结束时如何处理</li>
<li><code>.initialLayout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL</code> subpass 开始前 image subresource 的 layout</li>
<li><code>.finalLayout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL</code> subpass 结束后 image subresource 将会被自动转换到的 layout</li>
</ul>
</li>
<li><code>[1]</code>: Depth Stencil Attachment<ul>
<li><code>.format = demo-&gt;depth.format</code></li>
<li><code>.samples = VK_SAMPLE_COUNT_1_BIT</code></li>
<li><code>.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR</code></li>
<li><code>.storeOp = VK_ATTACHMENT_STORE_OP_DONT_CARE</code></li>
<li><code>.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE</code></li>
<li><code>.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE</code></li>
<li><code>.initialLayout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL</code></li>
<li><code>.finalLayout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL</code></li>
</ul>
</li>
</ul>
</li>
<li><code>.pSubpasses</code>: VkSubpassDescription<blockquote>
<p>A single render pass can consist of multiple subpasses. Subpasses are subsequent rendering operations that depend on the contents of framebuffers in previous passes, for example a sequence of post-processing effects that are applied one after another. If you group these rendering operations into one render pass, then Vulkan is able to reorder the operations and conserve memory bandwidth for possibly better performance. <a target="_blank" rel="noopener" href="https://vulkan-tutorial.com/Drawing_a_triangle/Graphics_pipeline_basics/Render_passes">Render passes - Vulkan Tutorial</a></p>
</blockquote>
<ul>
<li><code>.pipelineBindPoint = VK_PIPELINE_BIND_POINT_GRAPHICS</code> 该 subpass 支持的 pipeline 类型</li>
<li><code>.pInputAttachments = NULL</code></li>
<li><code>.pColorAttachments = &amp;color_reference</code><ul>
<li><code>VkAttachmentReference &#123;.attachment = 0, .layout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL&#125;</code><br>引用到上面的 <code>[0]</code></li>
</ul>
</li>
<li><code>.pDepthStencilAttachment = &amp;depth_reference</code><ul>
<li><code>VkAttachmentReference &#123;.attachment = 1, .layout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL&#125;</code><br>引用到上面的 <code>[1]</code></li>
</ul>
</li>
</ul>
</li>
<li><code>.pDependencies</code>: VkSubpassDependency 有多个 subpass 时指定 subpass 间的读写依赖关系<blockquote>
<p>和 vkCmdPipelineBarrier + VkMemoryBarrier 差不多，区别只是同步作用域限于指定的 subpass 间，而非所有在前在后的操作 (<a target="_blank" rel="noopener" href="https://registry.khronos.org/vulkan/specs/1.3-extensions/html/chap8.html#VkSubpassDependency">Vulkan Spec</a>)</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>demo_prepare_pipeline<ul>
<li>vkCreatePipelineCache: (<em>optional</em> for pipeline creation)<blockquote>
<p>主要用来供实现缓存编译好的 Pipeline; 可以使用 allocator 限制其缓存数据的大小; 可以创建时导入之前 (应用程序) 的 Cache 等</p>
</blockquote>
</li>
<li>vkCreateGraphicsPipelines<ul>
<li>VkGraphicsPipelineCreateInfo<ul>
<li><code>.layout = demo-&gt;pipeline_layout</code></li>
<li><code>.pVertexInputState</code>: VkPipelineVertexInputStateCreateInfo<ul>
<li>已经在 <code>demo_prepare_vertices</code> 中准备好</li>
</ul>
</li>
<li><code>.pInputAssemblyState</code>: VkPipelineInputAssemblyStateCreateInfo<ul>
<li><code>.topology = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST</code></li>
</ul>
</li>
<li><code>.pRasterizationState</code>: VkPipelineRasterizationStateCreateInfo<ul>
<li><code>.polygonMode = VK_POLYGON_MODE_FILL</code></li>
<li><code>.cullMode = VK_CULL_MODE_BACK_BIT</code></li>
<li><code>.frontFace = VK_FRONT_FACE_CLOCKWISE</code><ul>
<li>front-facing triangle orientation to be used for culling</li>
</ul>
</li>
<li><code>.depthClampEnable = VK_FALSE</code><ul>
<li>不启用深度截断</li>
</ul>
</li>
<li><code>.rasterizerDiscardEnable = VK_FALSE</code><ul>
<li>是否在光栅化阶段前立即丢弃片元</li>
</ul>
</li>
<li><code>.depthBiasEnable = VK_FALSE</code></li>
<li><code>.lineWidth = 1.0f</code><ul>
<li>光栅化线段宽度</li>
</ul>
</li>
</ul>
</li>
<li><code>.pColorBlendState</code>: VkPipelineColorBlendStateCreateInfo<ul>
<li><code>.pAttachments</code>: VkPipelineColorBlendAttachmentState，对每个 color attachment 定义 blend state<ul>
<li><code>[0]</code><ul>
<li><code>.colorWriteMask = 0xf</code><ul>
<li>写入 RGBA 全部四个通道 (<a target="_blank" rel="noopener" href="https://registry.khronos.org/vulkan/specs/1.3-extensions/html/chap29.html#framebuffer-color-write-mask">Vulkan Spec</a>)</li>
</ul>
</li>
<li><code>.blendEnable = VK_FALSE</code><ul>
<li>不启用 Blending，直接写入</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><code>.pMultisampleState</code>: VkPipelineMultisampleStateCreateInfo<ul>
<li><code>.rasterizationSamples = VK_SAMPLE_COUNT_1_BIT</code></li>
<li><code>.pSampleMask = NULL</code></li>
</ul>
</li>
<li><code>.pViewportState</code>: VkPipelineViewportStateCreateInfo<ul>
<li><code>.viewportCount = 1</code></li>
<li><code>.scissorCount = 1</code></li>
<li>不过这里用的 <strong>Dynamic State</strong>，也就是 Viewport 和 Scissor 的信息是在录制 Command Buffer 时提供的，创建 Pipeline 时不提供<ul>
<li>详情看 <code>.pDynamicState</code></li>
</ul>
</li>
</ul>
</li>
<li><code>.pDepthStencilState</code>: VkPipelineDepthStencilStateCreateInfo<ul>
<li><code>.depthTestEnable = VK_TRUE</code></li>
<li><code>.depthWriteEnable = VK_TRUE</code></li>
<li><code>.depthCompareOp = VK_COMPARE_OP_LESS_OR_EQUAL</code></li>
<li><code>.depthBoundsTestEnable = VK_FALSE</code><ul>
<li>Samples coverage &#x3D; 0 if outside the bound predetermined</li>
<li><a target="_blank" rel="noopener" href="https://registry.khronos.org/vulkan/specs/1.3-extensions/html/chap28.html#fragops-dbt">28.8. Depth Bounds Test</a></li>
</ul>
</li>
<li><code>.stencilTestEnable = VK_FALSE</code> 下面都是 Stencil test 的参数</li>
<li><code>.back.failOp = VK_STENCIL_OP_KEEP</code></li>
<li><code>.back.passOp = VK_STENCIL_OP_KEEP</code></li>
<li><code>.back.compareOp = VK_COMPARE_OP_ALWAYS</code></li>
<li><code>.front = ds.back</code></li>
</ul>
</li>
<li><code>.pStages</code>: VkPipelineShaderStageCreateInfo<ul>
<li><code>[0]</code><ul>
<li><code>.stage = VK_SHADER_STAGE_VERTEX_BIT</code></li>
<li><code>.pName = &quot;main&quot;</code></li>
<li><code>.module = demo_prepare_vs(demo)</code><ul>
<li>Call demo_prepare_shader_module with vert SPIR-V code<ul>
<li>vkCreateShaderModule with <code>size_t codeSize</code> &amp; <code>uint32_t *pCode</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><code>[1]</code><ul>
<li><code>.stage = VK_SHADER_STAGE_FRAGMENT_BIT</code></li>
<li><code>.pName = &quot;main&quot;</code></li>
<li><code>.module = demo_prepare_fs(demo)</code><ul>
<li>Similar with above</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><code>.pDynamicState</code>: VkPipelineDynamicStateCreateInfo<ul>
<li><code>.pDynamicStates = dynamicStateEnables</code><ul>
<li>启用了 <code>VK_DYNAMIC_STATE_VIEWPORT</code> 和 <code>VK_DYNAMIC_STATE_SCISSOR</code></li>
</ul>
</li>
</ul>
</li>
<li><code>.renderPass</code>: VkRenderPass<br>传入之前创建的 VkRenderPass</li>
</ul>
</li>
</ul>
</li>
<li>vkDestroyPipelineCache</li>
<li>vkDestroyShaderModule * 2<ul>
<li>删除 vs 和 fs 的两个刚才创建的 Shader Module (<code>demo_prepare_vs</code> &#x2F; <code>demo_prepare_fs</code>)</li>
</ul>
</li>
</ul>
</li>
<li>demo_prepare_descriptor_pool<ul>
<li>vkCreateDescriptorPool<ul>
<li>VkDescriptorPoolCreateInfo<ul>
<li><code>.pPoolSizes = &amp;type_count</code><ul>
<li>VkDescriptorPoolSize<ul>
<li><code>.type = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER</code></li>
<li><code>.descriptorCount = DEMO_TEXTURE_COUNT</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>demo_prepare_descriptor_set<ul>
<li>vkAllocateDescriptorSets：按 Descriptor Set Layouts 从 Descriptor Pool 中分配 Descriptor Sets<ul>
<li><code>.pSetLayouts = &amp;demo-&gt;desc_layout</code></li>
<li><code>.descriptorPool = demo-&gt;desc_pool</code></li>
</ul>
</li>
<li>vkUpdateDescriptorSets<br>支持 Write 和 Copy 两种形式的 Descriptor Set 更新请求<ul>
<li>VkWriteSescriptorSet<ul>
<li><code>.dstSet = demo-&gt;desc_set</code> 刚分配的 Descriptor Set</li>
<li><code>.descriptorCount = DEMO_TEXTURE_COUNT</code></li>
<li><code>.descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER</code></li>
<li><code>.pImageInfo = tex_descs</code><ul>
<li>VkDescriptorImageInfo: 具体的 Descriptor 内容<ul>
<li><code>.sampler = demo-&gt;textures[i].sampler</code></li>
<li><code>.imageView = demo-&gt;textures[i].view</code></li>
<li><code>.imageLayout = VK_IMAGE_LAYOUT_GENERAL</code><blockquote>
<p>感觉这里应该是选对应的才对，不知道这样可以不可以</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>demo_prepare_framebuffers<ul>
<li>创建 <code>demo-&gt;swapchainImageCount</code> 个 VkFramebuffer<ul>
<li>vkCreateFramebuffer<ul>
<li>VkFramebufferCreateInfo<ul>
<li><code>.renderPass = demo-&gt;renderpass</code></li>
<li><code>.pAttachments</code>: VkImageView[]<ul>
<li><code>[0]</code>: Color Attachment, <code>demo-&gt;buffers[i].view</code><ul>
<li>That is, the swapchain image view</li>
</ul>
</li>
<li><code>[1]</code>: Depth Attachment<ul>
<li><code>demo-&gt;depth.view</code></li>
</ul>
</li>
</ul>
</li>
<li><code>.width</code>, <code>.height</code></li>
<li><code>.layers = 1</code><blockquote>
<p>正如 VkImage 创建时也可以选择多 layer 一样，这里也可以；不过 Shader 默认写入第一层，除了 Geometry Shader</p>
<p>多 layer 的 Image &#x2F; Framebuffer 在 Shader 里面是用的 texture array 的语法来访问的</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>demo_run<ul>
<li>glfwWindowShouldClose: 检测窗口的 closing 标志</li>
<li>glfwPollEvent</li>
<li>demo_draw<ul>
<li>vkCreateSemaphore: <code>imageAcquiredSemaphore</code></li>
<li>vkCreateSemaphore: <code>drawCompleteSemaphore</code></li>
<li>vkAcquireNextImageKHR<blockquote>
<p>这里有一个问题，这里返回并不意味着 Present 完成 (推荐做法是 Present 设置 Semaphore，然后等 Semaphore)</p>
<p>那么，什么情况下这里会 block？<br>也可以参考 <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/64150186/lets-get-swapchains-image-count-straight">Let’s get swapchain’s image count straight - StackOverflow</a></p>
</blockquote>
<ul>
<li><code>timeout = UINT64_MAX</code></li>
<li><code>semaphore = imageAcquiredSemaphore</code></li>
<li><code>pImageIndex = &amp;demo-&gt;current_buffer</code>: index of the next image to use<ul>
<li>完成后会 signal 该 semaphore</li>
</ul>
</li>
<li>返回值<ul>
<li>VK_ERROR_OUT_OF_DATE_KHR<ul>
<li>demo_resize: 处理 resize 情况：<strong>Destroy everything</strong><ul>
<li>vkDestroyFramebuffer</li>
<li>vkDestroyDescriptorPool</li>
<li>vkFreeCommandBuffers</li>
<li>vkDestroyCommandPool</li>
<li>vkDestroyPipeline</li>
<li>vkDestroyRenderPass</li>
<li>vkDestroyPipelineLayout</li>
<li>vkDestroyDescriptorSetLayout</li>
<li>vkDestroyBuffer (vertex buffer)</li>
<li>vkFreeMemory (vertex buffer memory)</li>
<li>vkDestroyImageView</li>
<li>vkDestroyImage</li>
<li>vkDestroySampler</li>
<li>…</li>
<li>call <code>demo_prepare</code></li>
</ul>
</li>
<li>demo_draw: 重复调用一下自己</li>
</ul>
</li>
<li>VK_SUBOPTIMAL_KHR: 不是最优，但是也能 present，所以不管</li>
</ul>
</li>
</ul>
</li>
<li>demo_flush_init_cmd: 同步方式 flush setup cmd<ul>
<li>vkEndCommandBuffer</li>
<li>vkQueueSubmit<ul>
<li>no wait &#x2F; signal semaphores</li>
</ul>
</li>
<li>vkQueueWaitIdle</li>
<li>vkFreeCommandBuffers</li>
<li><code>demo-&gt;setup_cmd = VK_NULL_HANDLE</code></li>
</ul>
</li>
<li>demo_draw_build_cmd<ul>
<li>vkBeginCommandBuffer: <code>demo-&gt;draw_cmd</code></li>
<li>vkCmdPipelineBarrier<ul>
<li>Execution barrier 部分<ul>
<li><code>srcStageMask = VK_PIPELINE_STAGE_ALL_COMMANDS_BIT</code>，也就是 wait for everything</li>
<li><code>dstStageMask = VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT</code> (Specifies no stage of execution)<blockquote>
<p><code>VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT</code> is equivalent to <code>VK_PIPELINE_STAGE_ALL_COMMANDS_BIT</code> with VkAccessFlags set to 0 when specified in the first synchronization scope, but specifies no stage of execution when specified in the second scope.</p>
</blockquote>
</li>
</ul>
</li>
<li>Memory barrier 部分: 对 color attachment 做 layout transition<ul>
<li>从 <code>VK_IMAGE_LAYOUT_UNDEFINED</code> -&gt; <code>VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL</code></li>
<li><code>.dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT</code></li>
</ul>
</li>
</ul>
</li>
<li>vkCmdBeginRenderPass with <code>VK_SUBPASS_CONTENTS_INLINE</code><blockquote>
<p><code>VK_SUBPASS_CONTENTS_INLINE</code> specifies that the contents of the subpass will be recorded inline in the primary command buffer, and secondary command buffers must not be executed within the subpass.</p>
</blockquote>
<ul>
<li>VkRenderPassBeginInfo<ul>
<li><code>.renderPass</code></li>
<li><code>.framebuffer</code> - 选择<strong>当前</strong>的 framebuffer，我们有 <code>swapchainImageCount</code> 个</li>
<li><code>.renderArea</code><ul>
<li><code>.offset.&#123;x, y&#125;</code></li>
<li><code>.extent.&#123;width, height&#125;</code></li>
</ul>
</li>
<li><code>.pClearValues = clear_values</code> (VkClearValue)<blockquote>
<p>这里是和 RenderPassCreateInfo 指定的 attachments 相对应的</p>
<p><code>pClearValues</code> is a pointer to an array of <code>clearValueCount</code> VkClearValue structures containing clear values for each attachment, if the attachment uses a <code>loadOp</code> value of <code>VK_ATTACHMENT_LOAD_OP_CLEAR</code> or if the attachment has a depth&#x2F;stencil format and uses a <code>stencilLoadOp</code> value of <code>VK_ATTACHMENT_LOAD_OP_CLEAR</code>. The array is indexed by attachment number. Only elements corresponding to cleared attachments are used. Other elements of pClearValues are ignored.</p>
</blockquote>
<ul>
<li><code>[0] = &#123;.color.float32 = &#123;0.2f, 0.2f, 0.2f, 0.2f&#125;&#125;</code></li>
<li><code>[1] = &#123;.depthStencil = &#123;demo-&gt;depthStencil, 0&#125;&#125;</code><ul>
<li><code>demo-&gt;depthStencil</code> 用来加一个“无形的墙”</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>vkCmdBindPipeline<ul>
<li><code>pipelineBindPoint = VK_PIPELINE_BIND_POINT_GRAPHICS</code></li>
</ul>
</li>
<li>vkCmdBindDescriptorSets<ul>
<li><code>layout = demo-&gt;pipeline_layout</code><br>Recall: Pipeline layout &lt;&#x3D; Descriptor Set Layouts</li>
<li>Descriptor Sets</li>
</ul>
</li>
<li>vkCmdSetViewport<ul>
<li>VkViewport<ul>
<li><code>.height</code>, <code>.width</code>, <code>.minDepth</code>, <code>.maxDepth</code></li>
</ul>
</li>
</ul>
</li>
<li>vkCmdSetScissor<ul>
<li>VkRect2D<ul>
<li><code>.extent.&#123;width, height&#125;</code></li>
<li><code>.offset.&#123;x, y&#125;</code></li>
</ul>
</li>
</ul>
</li>
<li>vkCmdBindVertexBuffers<blockquote>
<p>看 <a target="_blank" rel="noopener" href="https://github.com/SaschaWillems/Vulkan/blob/master/examples/instancing/instancing.cpp">https://github.com/SaschaWillems/Vulkan/blob/master/examples/instancing/instancing.cpp</a> 可能会印象更深刻</p>
</blockquote>
<ul>
<li>firstBinding 参数用于 (CPU 端) 指定绑定到哪里</li>
</ul>
</li>
<li>vkCmdDraw<ul>
<li><code>vertexCount = 3</code></li>
<li><code>instanceCount = 1</code></li>
<li><code>firstVertex = 0</code></li>
<li><code>firstInstance = 0</code></li>
</ul>
</li>
<li>vkCmdEndRenderPass</li>
<li>vkCmdPipelineBarrier<ul>
<li>Execution barrier:<ul>
<li><code>srcStageMask = VK_PIPELINE_STAGE_ALL_COMMANDS_BIT</code>，也就是 wait for everything</li>
<li><code>dstStageMask = VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT</code> (Specifies no stage of execution)</li>
</ul>
</li>
<li>Memory barrier:<blockquote>
<p>正如 transfer，present 也需要 layout 改变</p>
</blockquote>
<ul>
<li><code>.srcAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT</code></li>
<li><code>.dstAccessMask = VK_ACCESS_MEMORY_READ_BIT</code></li>
<li><code>.oldLayout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL</code></li>
<li><code>.newLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR</code></li>
</ul>
</li>
</ul>
</li>
<li>vkEndCommandBuffer: <code>demo-&gt;draw_cmd</code></li>
</ul>
</li>
<li>vkQueueSubmit<ul>
<li><code>.pCommandBuffers = &amp;demo-&gt;draw_cmd</code></li>
<li><code>.pWaitSemaphores = &amp;imageAcquiredSemaphore</code></li>
<li><code>.pWaitDstStageMask = &amp;pipe_stage_flags</code><ul>
<li><code>pWaitDstStageMask</code> is a pointer to an array of pipeline stages at which each corresponding semaphore wait will occur.</li>
<li>这里设置成了 <code>VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT</code></li>
<li>所以，相当于啥也没等</li>
</ul>
</li>
<li><code>.pSignalSemaphores = &amp;drawCompleteSemaphore</code></li>
</ul>
</li>
<li>vkQueuePresentKHR<ul>
<li>VkPresentInfoKHR<ul>
<li><code>.pWaitSemaphores = &amp;drawCompleteSemaphore</code></li>
<li><code>.pSwapchains = &amp;demo-&gt;swapchain</code><ul>
<li>可以多个，用来支持多个 swapchain 用一个 queue present 操作进行 present</li>
</ul>
</li>
<li><code>.pImageIndices = &amp;demo-&gt;current_buffer</code></li>
</ul>
</li>
<li>返回值<ul>
<li>VK_ERROR_OUT_OF_DATE_KHR<ul>
<li>demo_resize</li>
</ul>
</li>
<li>VK_SUBOPTIMAL_KHR<ul>
<li>啥事不干</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>vkQueueWaitIdle</li>
<li>vkDestroySemaphore: <code>imageAcquiredSemaphore</code></li>
<li>vkDestroySemaphore: <code>drawCompleteSemaphore</code></li>
</ul>
</li>
<li>demo-&gt;depthStencil 周期改变</li>
<li>vkDeviceWaitIdle</li>
<li>如果到了指定的帧数，则 glfwSetWindowShouldClose</li>
</ul>
</li>
<li>demo_cleanup<ul>
<li>删除一万个东西 (literally)</li>
<li>glfwDestroyWindow</li>
<li>glfwTerminate</li>
</ul>
</li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
    -->
  </div>
  
</article>



    
      <article id="paper-reading-paper-reading/data-driven-prt" class="article article-type-paper-reading" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/paper-reading/data-driven-prt/"><strong>论文阅读 | 数据驱动的 PRT</strong></a>
      <small class=article-date-index>&nbsp; 2022-12-18</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/paper-reading/data-driven-prt/" class="article-date">
  <time datetime="2022-12-17T16:00:00.000Z" itemprop="datePublished">2022-12-18</time>
</a>-->
      <!--
-->
      <!--
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>本文省略了一大堆细节，详情参见论文。</p>
<p>TODO: 整理清楚各个维数，因为原论文也不甚详细；</p>
<p>更新后的版本会放到 <a href="https://blog.libreliu.info/paper-reading/data-driven-prt/">这里</a>，如果有。</p>
</blockquote>
<h2 id="Recap-Precomputed-Radiance-Transfer"><a href="#Recap-Precomputed-Radiance-Transfer" class="headerlink" title="Recap: Precomputed Radiance Transfer"></a>Recap: Precomputed Radiance Transfer</h2><blockquote>
<p>本节主要参考<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1YK4y1T7yY">GAMES 202 - 高质量实时渲染</a>课程的 Lecture 6 和 Lecture 7</p>
</blockquote>
<p>考虑渲染方程</p>
$$
L({\bf o}) = \int_{\mathcal{H}^2} L({\bf i}) \rho({\bf i}, {\bf o}) V({\bf i}) \max(0, {\bf n} \cdot {\bf i}) d {\bf i}
$$

<p>其中</p>
<ul>
<li>$ {\bf i}, {\bf o} $ 为入射和出射方向</li>
<li>$ L({\bf i}), L({\bf o}) $ 为入射和出射 radiance<ul>
<li>此处<strong>省略了</strong>作为参数的 shading point 位置 $ \bf x $，下同</li>
</ul>
</li>
<li>$ \rho $ 为 BRDF 函数</li>
<li>$ V $ 为 Visibility 项</li>
</ul>
<p>将 $ L({\bf i}) $ 项用级数的有限项进行近似，即</p>
$$
L({\bf i}) \approx \sum_{i=1}^{n} l_i B_i({\bf i})
$$

<blockquote>
<p>其中 $ B_i: S^2 \to \mathbb{R} $ 为基函数</p>
</blockquote>
<p>带入得到</p>
$$
\begin{aligned}
L({\bf o}) &= \int_{\mathcal{H}^2} L({\bf i}) \rho({\bf i}, {\bf o}) V({\bf i}) \max(0, {\bf n} \cdot {\bf i}) d {\bf i} \\
&\approx \sum_i l_i \int_{\mathcal{H}^2} B_i({\bf i}) \rho({\bf i}, {\bf o}) V({\bf i}) \max(0, {\bf n} \cdot {\bf i}) d {\bf i} \\
&= \sum_i l_i T_i({\bf o})
\end{aligned}
$$

<p>这里把上面的积分 (“Light transport term”) 记作 $ T_i $.</p>
<p>这里继续进行展开</p>
$$
T_i({\bf o}) \approx \sum_{j=1}^{m} t_{ij} B_j({\bf o})
$$

<p>所以我们得到</p>
$$
\begin{aligned}
L({\bf o}) &\approx \sum_i l_i T_i({\bf o}) \\
&\approx \sum_i l_i \left( \sum_j t_{ij} B_j({\bf o}) \right) \\
&\approx \sum_j \left( \sum_i l_i t_{ij} \right) B_j({\bf o}) \\
\end{aligned}
$$

<p>也就是说</p>
$$
L({\bf o}) 
\approx 
\begin{bmatrix}
l_1 & ... & l_n
\end{bmatrix}
\begin{bmatrix}
t_{11} & ... & t_{1m} \\
\vdots & & \vdots \\
t_{n1} & ... & t_{nm}
\end{bmatrix}
\begin{bmatrix}
B_1({\bf o}) \\ \vdots \\ B_m({\bf o})
\end{bmatrix}
$$

<p>那么，PRT 的框架就大致如下</p>
<ol>
<li><p>预计算</p>
<ul>
<li>对每个可能的 shading point $ {\bf x} $<ul>
<li>计算该物体的环境光在基函数下对应的系数 $ l_i $</li>
<li>计算该物体光传输展开系数 $ t_{ij} $</li>
</ul>
</li>
</ul>
<blockquote>
<p>当然，对于 Image based lighting，一般认为 $ L({\bf i}, {\bf x}) \approx L({\bf i}) $，那某些东西就不需要 per-shading point 存储</p>
</blockquote>
</li>
<li><p>运行时</p>
<ul>
<li>根据视角 $ {\bf o} $ 和位置 $ {\bf x} $ 来读取对应的向量并计算</li>
</ul>
</li>
</ol>
<blockquote>
<p>对于 Diffuse 物体，$ \rho({\bf i}, {\bf o}) $ 是常数，所以不需要继续展开 $ T_i $ 项</p>
</blockquote>
<blockquote>
<p>Remarks from paper: PRT methods bake the transport matrix using implicit light sources defined by the illumination basis.<br>Those light sources shade the asset with positive and negative radiance values. Hence, a dedicated light transport algorithm is used for them.</p>
</blockquote>
<h2 id="本文思路"><a href="#本文思路" class="headerlink" title="本文思路"></a>本文思路</h2><p>本文的框架只考虑<strong>漫反射</strong>，虽然结果上对于不是特别 Glossy 的材质应该都可以应用。</p>
<p>框架上的思路就是</p>
<ul>
<li>间接光 $ L_i({\bf x}; t) $ 和直接光 $ L_d({\bf i}, {\bf x}; t) $ 之间存在线性关系</li>
<li>框架：<ul>
<li>将 $ {\bf x} $ 和 $ i \times t $ 所在空间分别做一离散化，得到 $ I &#x3D; MD $<ul>
<li>相当于挑了一组基，每个基内部由同一个光照条件下各个位置的 $ L_d $ 组成</li>
</ul>
</li>
<li>对于给定的光照条件 $ x $ （各个位置 $ L_d $的值构成的列向量） ，如何求解 $ L_i $ ？<ul>
<li>首先把 $ x $ 分解到该 $ D $ 基下，得到系数向量 $ c &#x3D; (D^T D)^{-1} D^T x $</li>
<li>每个 $ D $ 基我们都存储有对应的输出，所以结果 $ y &#x3D; Mx &#x3D; I(D^T D)^{-1} D^T x $</li>
</ul>
</li>
</ul>
</li>
<li>近似：<ul>
<li>对 $ I $ 进行 SVD 分解并保留前 $ k $ 项，得到近似矩阵 $ I &#x3D; U \Sigma V^T \approx U_n \Sigma_n V_n^T $</li>
<li>$ y \approx U_n (\Sigma_n V_n^T) (D^T D)^{-1} D^T x $<ul>
<li>let $ M_n &#x3D; (\Sigma_n V_n^T) (D^T D)^{-1} D^T $</li>
</ul>
</li>
<li>存储 $ U_n $ 和 $ M_n $</li>
</ul>
</li>
<li>运行时：<ul>
<li>用 G-Buffer 得到 $ \mathcal{X}_D $ 空间上的各 $ L_d({\bf i}, {\bf x}; t) $ 的值</li>
<li>计算 $ y &#x3D; U_n M_n x $ 的值</li>
</ul>
</li>
</ul>
<h3 id="估计光传输矩阵"><a href="#估计光传输矩阵" class="headerlink" title="估计光传输矩阵"></a>估计光传输矩阵</h3><p>给定<strong>环境光</strong>条件 $ t \in \mathcal T $，那么在物体表面 $ {\bf x} $ 处，<strong>漫反射</strong>光传输方程的形式如下</p>
$$
L_i({\bf x}; t) = \frac{1}{2 \pi}\int_{\mathcal{H}^2} L_d({\bf i}, {\bf x}; t) V({\bf i}, {\bf x}) \max(0, {\bf n} \cdot {\bf i}) d {\bf i}
$$

<p>其中，$ L_i({\bf x}; t) $ 被称为间接光， $ L_d({\bf i}, {\bf x}; t) $ 被称为直接光</p>
<blockquote>
<p>$ L_d({\bf i}, {\bf x}; t) $ 不考虑环境和物体 inter-reflection; 推导中可以先忽略，虽然实际上对于有 inter-transmission 的情况应该也是可以应用的</p>
</blockquote>
<p>现在将 $ {\bf x} $ 和 $ i \times t $ 所在空间分别做一离散化，得到 $ \mathcal{X}_D $ 和 $ \mathcal{T}_D $ 两有限维空间，那么在这两个空间上， $ L_d $ 和 $ L_i $ 都可以表示为矩阵形式，这里规定每一列的元素在同一个环境光条件 $ {\bf i}, t $ 上。</p>
<blockquote>
<p>比如说，都在环境光为某点光源照射的情况； $ L_d({\bf i}, {\bf x}; t) $ 的 $ {\bf i} $ 一般意义上是依赖 $ t $ 的</p>
</blockquote>
<p>记得到的两个矩阵为 $ D $ 和 $ I $，则</p>
$$
I_k = f(D_k) \quad \forall k \in [0, |\mathcal{T}_D|]
$$

<p>从前面可以看到，这里的 $f$ 是线性算子 (<em>是嘛？</em>)，所以</p>
$$
I = MD
$$

<p>又假设我们离散 $ \mathcal T $ 空间离散的很好，那么对任意的环境光条件，<strong>直接光向量</strong> $ x $ 都可以表示成 $ D $ 的线性组合，满足</p>
$$
x = Dc
$$

<p>左右乘 $ M $ 得到</p>
$$
Mx = MDc = Ic
$$

<p>也就是说 $x$ 产生的间接光照可以用 $I$ 中列向量的线性组合来表示</p>
<p>因为 $ x &#x3D; Dc $，假设 $ D^T D $ 可逆，那么用左逆得到</p>
$$
c = (D^T D)^{-1} D^T x
$$

<p>那么</p>
$$
y = Mx = Ic = I (D^T D)^{-1} D^T x
$$

<p>这样就给出了<strong>任意直接光经过光传输</strong>的结果</p>
<h3 id="间接光基函数"><a href="#间接光基函数" class="headerlink" title="间接光基函数"></a>间接光基函数</h3><p>我们认为，间接光所对应的空间的秩比较低，所以用 SVD 分解然后保留前 $ n $ 项</p>
$$
I = U \Sigma V^T \approx U_n \Sigma_n V_n^T = U_n C_n
$$

<p>其中记 $ C_n &#x3D; \Sigma_n V_n^T $</p>
<p>带回去，得到任意直接光组合经过光传输方程的近似结果</p>
$$
\begin{aligned}
y &\approx U_n C_n (D^T D)^{-1} D^T x \\
&\approx U_n M_n x
\end{aligned}
$$

<p>其中 $ M_n &#x3D; C_n (D^T D)^{-1} D^T $</p>
<h3 id="直接光编码"><a href="#直接光编码" class="headerlink" title="直接光编码"></a>直接光编码</h3><p>如果有需要的话，可以考虑 SH 基函数，详见文章</p>
<h2 id="对比经典-PRT"><a href="#对比经典-PRT" class="headerlink" title="对比经典 PRT"></a>对比经典 PRT</h2><p>First, because classical PRT restricts the frequency content of the incoming lighting, we can see that the directional light leaks behind the object. Our method <strong>does not restrict the frequency content of incoming light</strong> but rather <strong>the space of possible indirect illumination</strong>.  Hence, we can better reproduce such lighting scenario. </p>
<p>Furthermore, classical PRT is performed on the vertices of the asset. This can cause interpolation artifacts when the asset is poorly tessellated, and it also links performance to the vertex count. Since we rely on a <strong>meshless approach</strong>, we are free of issues.</p>
<h2 id="局限"><a href="#局限" class="headerlink" title="局限"></a>局限</h2><p><strong>Sparse Illumination Measurement</strong>. As shown in Section 3.3, the sampling of the measurement points is linked to the achievable lighting dimensionality. Thus, it needs to be sufficiently dense to reproduce the space of observable lighting configurations. It follows that a lighting scenario mixing many light types might require a denser sampling. </p>
<p><strong>No Directionality</strong>. We reconstruct a diffuse appearance when reconstructing indirect illumination. However, since our method does not depend on the encoding of the measured indirect illumination, it can be extended to reconstruct glossy appearances e.g. directional distributions using directional sampling or any basis such as Spherical Harmonics. However, our method is likely to be restricted to low frequency gloss here and will not work to render specular reflections. </p>
<p><strong>Large Assets</strong>. Our solution is not designed to handle assets such as levels in a game. Because we handle light transport globally and reduce it with a handful of basis functions, we cannot reconstruct the interconnected interiors or large environments in which the combinatorics of possible illumination is large. For such case, our method would require to be extended to handle modular transfer between disjoint transport solutions (Similar to Loos et al. [2011]).</p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
    -->
  </div>
  
</article>



    
      <article id="paper-reading-paper-reading/continuous-mis" class="article article-type-paper-reading" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/paper-reading/continuous-mis/"><strong>论文阅读 | 连续多重重要性采样</strong></a>
      <small class=article-date-index>&nbsp; 2022-11-05</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/paper-reading/continuous-mis/" class="article-date">
  <time datetime="2022-11-04T16:00:00.000Z" itemprop="datePublished">2022-11-05</time>
</a>-->
      <!--
-->
      <!--
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>本篇文章扩展了 Veach 在 1995 年提出的、用于 Monte Carlo 多重重要性采样 (Multiple Importance Sampling)，将其推广到了具有<strong>无限</strong>的<strong>连续</strong>采样策略的情况。</p>
<h2 id="多重重要性采样-MIS"><a href="#多重重要性采样-MIS" class="headerlink" title="多重重要性采样 (MIS)"></a>多重重要性采样 (MIS)</h2><blockquote>
<p>本方法比较详细的讨论可以参考 <em>Optimally Combining Sampling Techniques<br>for Monte Carlo Rendering</em> 这篇 SIGGRAPH’95 的论文，是 Veach 和 Guibas 很高引用的文章之一。</p>
<p>也可以参考 <a target="_blank" rel="noopener" href="https://www.pbr-book.org/3ed-2018/Monte_Carlo_Integration/Importance_Sampling">Importance Sampling | PBR Book 3rd</a>，不过里面没有证明。</p>
</blockquote>
<p>对于积分</p>
$$
I = \int_\Omega f(x) dx
$$

<p>我们希望用 Monte Carlo 采样的方法进行积分值的估计。</p>
<p>多重重要性采样 (Multiple Importance Sampling, MIS) 的大致思路如下：有 $ m $ 个采样策略，每个采样策略都可以对样本空间 $ \Omega $ 进行采样，并且每种策略都有概率密度函数 $ p_i(x) $。</p>
<p>对于 Multi-sample MIS，要分别使用每种采样策略<strong>独立</strong>采样 $ n_i $ 次，获得总计 $ \sum_{i&#x3D;1}^{m} n_i $ 个采样，然后使用如下的式子进行积分的估计：</p>
$$
\langle I \rangle_{mis} = \sum_{i=1}^m \frac{1}{n_i} \sum_{j=1}^{n_i} \frac{w_i(x_{i,j}) f(x_{i, j})}{p_i(x_{i,j})}
$$

<p>其中 $ x_{i, j} $ 表示第 $ i $ 个采样策略第 $ j $ 次采样获得的值，$ w_i(x) $ 为 $ m $ 个与 MIS 相关的权重函数。</p>
<p>首先可以证明，这 $ m $ 个权重函数只要满足 $ \sum_{i&#x3D;1}^m w_i(x) &#x3D; 1 $，那么 $ \langle I \rangle_{mis} $ 就是无偏的：</p>
$$
\begin{aligned}
\operatorname{E}[\langle I \rangle_{mis}] &= \operatorname{E}\left[ \sum_{i=1}^m \frac{1}{n_i} \sum_{j=1}^{n_i} \frac{w_i(x_{i,j}) f(x_{i, j})}{p_i(x_{i,j})} \right] \\
&= \sum_{i=1}^m \frac{1}{n_i} \operatorname{E}\left[ \sum_{j=1}^{n_i} \frac{w_i(x_{i,j}) f(x_{i, j})}{p_i(x_{i,j})} \right] \\
&= \sum_{i=1}^m \operatorname{E}\left[ \frac{w_i(x_{i,1}) f(x_{i, 1})}{p_i(x_{i,1})} \right] \quad (\because \text{i.i.d})\\
&= \sum_{i=1}^m \int_\Omega \frac{w_i(x) f(x)}{p_i(x)} p_i(x) dx \\
&= \sum_{i=1}^m \int_\Omega w_i(x) f(x) dx \\
&= \int_\Omega \sum_{i=1}^m w_i(x) f(x) dx \\
&= \int_\Omega f(x) dx \\
&= I
\end{aligned}
$$

<p>那么，哪样的权重会让估计量的方差比较小呢？Veach 和 Guibas 在其论文中，给出了被称为 <strong>Balance Heuristic</strong> 的估计量：</p>
$$
\hat w_i (x) = \frac{c_i p_i(x)}{\sum_{j=1}^m c_j p_j(x)} \quad \text{where}\ c_i = n_i / \sum_{j=1}^{m} n_j 
$$

<p>并且他们证明了，使用 $ { \hat w_i(x) }<em>{i&#x3D;1}^m $ 作为权重函数构造的估计量 $ \langle \hat I</em>{mis} \rangle $ 和<strong>任意的</strong>权重函数构造的估计量 $ \langle I_{mis} \rangle $ 的方差满足下面的关系：</p>
$$
\operatorname{V}[\langle \hat I \rangle_{mis}] \le \operatorname{V}[\langle I \rangle_{mis}] + \left( \frac{1}{\min_i n_i} - \frac{1}{\sum_i n_i} \right) I^2 
$$

<p>这其实在说，Balance Heuristic 从渐进意义上来说是方差比较低的估计。</p>
<p>有的时候，我们只希望采样一次。这种情况下，我们可以首先以 $P(t&#x3D;i)$ 的概率去采样我们将要使用的采样方法 $t$，然后再使用 MIS 积分估计量：</p>
$$
\langle I \rangle_{mis} = \frac{w_t(x_{t,1}) f(x_{t,1})}{p_t(x_{t,1}) P(t=i)}
$$

<p>其中 $ p_t(x_{t,1}) $ 表示采样方法为 $ t $ 情况下抽样到 $ x_{t,1} $ 的条件概率。</p>
<p>Veach 的论文中证明，Balance Heuristic 在任何 One-sample MIS 的情形下都是最优的权重组合。</p>
<h2 id="连续多重重要性采样-Continuous-MIS"><a href="#连续多重重要性采样-Continuous-MIS" class="headerlink" title="连续多重重要性采样 (Continuous MIS)"></a>连续多重重要性采样 (Continuous MIS)</h2><p>West 等人将上面的工作进行了进一步的推广：如果现在有连续的无限多种采样策略，那么也可以将 MIS 中的估计量进行推广，得到<strong>连续多重重要性采样</strong> (Continuous Multiple Importance Sampling, CMIS)。</p>
<p>定义采样方法空间 $ \mathcal{T} $，在其上的每个元素 $ t \in \mathcal{T} $ 都是一种采样策略。</p>
<p>那么自然可以想到，将 $ w_i(x) $ 推广为一个 $ \mathcal{T} \times \mathcal{X} \to \mathrm{R} $ 的函数 $ w(t, x) $，归一化条件 $ \sum_i w_i(x) &#x3D; 1 $ 推广为 $ \int_\mathcal{T} w(t, x) dt &#x3D; 1 $。</p>
<p>类似的，可以定义 One-sample CMIS 积分估计量</p>
$$
\langle I \rangle_{CMIS} = \frac{w(t, x)f(x)}{p(t, x)} = \frac{w(t, x)f(x)}{p(t) p(x|t)}
$$

<p>其中 $ p(t) $ 是选择策略 $ t $ 的概率密度， $ p(x|t) $ 是在策略 $ t $ 下采样得到 $ x $ 的条件概率。</p>
<p>同时，只要满足如下两个条件，上面的估计量就是无偏的：</p>
<ol>
<li>$ \int_\mathcal{T} w(t, x) dt = 1 $ 对任何 $ x \in \operatorname{supp} f(x) $ 成立</li>
<li>当 $ p(t, x) &#x3D; 0 $ 时，$ w(t, x) &#x3D; 0 $ <blockquote>
<p>为什么？</p>
</blockquote>
</li>
</ol>
<p>类比 MIS，CMIS 也可以定义 Balance Heuristic 如下：</p>
$$
\bar w(t, x) = \frac{p(t)p(x|t)}{\int_\mathcal{T} p(t') p(x|t') dt'} = \frac{p(t, x)}{\int_\mathcal{T} p(t', x)dt} = \frac{p(t, x)}{p(x)}
$$

<blockquote>
<p>那么其实可以看到，用 Balance Heristic 的 $ w(t, x) $ 带入到 $ \langle I \rangle_{CMIS} $ 之后，其实就会化简成为 $ f(x) &#x2F; p(x) $，只不过这里的 $ p(x) $ 是 $ p(t, x) $ 的边缘分布。</p>
</blockquote>
<h2 id="随机多重重要性采样-Stochastic-MIS"><a href="#随机多重重要性采样-Stochastic-MIS" class="headerlink" title="随机多重重要性采样 (Stochastic MIS)"></a>随机多重重要性采样 (Stochastic MIS)</h2><p>前面的方法会面临一个问题，有的时候 $ p(x) &#x3D; \int_\mathcal{T} p(t’, x)dt $ 是没有闭式解的，这样去算 $ \bar w(t, x) $ 的时候会遇到问题。所以，West 等人又提出了随机多重重要性采样 (Stochastic MIS, SMIS)。</p>
<p>SMIS 首先假设在 $ \mathcal{T} \times \mathcal{X} $ 中独立的采样 $ (t_1, x_1), …, (t_n, x_n) $ 共 $n$ 组点。</p>
<blockquote>
<p>TODO: implement me</p>
</blockquote>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><h4 id="Path-Reuse"><a href="#Path-Reuse" class="headerlink" title="Path Reuse"></a>Path Reuse</h4><h4 id="Spectral-Rendering"><a href="#Spectral-Rendering" class="headerlink" title="Spectral Rendering"></a>Spectral Rendering</h4><h4 id="Volume-Single-Scattering"><a href="#Volume-Single-Scattering" class="headerlink" title="Volume Single Scattering"></a>Volume Single Scattering</h4>
      
    </div>
	
    <!--
	
    -->
    <!--
    
    -->
  </div>
  
</article>



    
      <article id="post-example-d3d11-app-flow" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/example-d3d11-app-flow/"><strong>一个示例 D3D11 程序的全流程记录</strong></a>
      <small class=article-date-index>&nbsp; 2022-10-19</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/example-d3d11-app-flow/" class="article-date">
  <time datetime="2022-10-18T16:00:00.000Z" itemprop="datePublished">2022-10-19</time>
</a>-->
      <!--
-->
      <!--
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>本篇是笔者进行 RenderDoc drivers 层分析时一并记录下来的，是一个渲染 Cube 的简单 D3D11 程序与 API 交互的全流程的记录。</p>
<p>以 <a target="_blank" rel="noopener" href="https://github.com/libreliu/DirectX11-With-Windows-SDK/tree/master/Project%2001-09/03%20Rendering%20a%20Cube">DirectX11-With-Windows-SDK - Rendering A Cube</a> 为例进行说明。</p>
<blockquote>
<p>DXGI (<strong>D</strong>irect<strong>X</strong> <strong>G</strong>raphics <strong>I</strong>nfrastructure) 负责抽象和交换链、DAL 相关的公共部分。关于 DXGI 的资料可以参考 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/windows/win32/direct3ddxgi/d3d10-graphics-programming-guide-dxgi">MSDN</a>。</p>
<p>DXGI 封装了多种对象：</p>
<ul>
<li>显示适配器 (IDXGIAdapter): 一般对应一块显卡，也可以对应 Reference Rasterizer，或者支持虚拟化的显卡的一个 VF 等</li>
<li>显示输出 (IDXGIOutput): 显示适配器的输出，一般对应一个显示器</li>
<li>交换链 (IDXGISwapChain): 用来暂存要显示到输出窗口&#x2F;全屏幕的 1 到多个 Surface 的对象<ul>
<li><code>g_pSwapChain-&gt;GetBuffer</code> 可以拿到表示 Back Buffer 的 <code>ID3D11Texture</code></li>
<li>从 <code>g_pd3dDevice-&gt;CreateRenderTargetView</code> 来创建一个封装该 Texture 的 <code>ID3D11RenderTargetView</code></li>
<li><code>g_pd3dDeviceContext-&gt;OMSetRenderTargets</code> 来设置管线的 RenderTarget</li>
<li><code>g_pd3dDeviceContext-&gt;RSSetViewports</code> 来设置管线的 Viewport</li>
</ul>
</li>
</ul>
</blockquote>
<!--

> 和 DRM (master) 的相应概念的对比：
> - NOTE: 我只看过 DRM Master (?) 的相关 API
> 
> DRM 里面有
> - KMS:
>   - CRT Controller, Encoder, Connector, Plane
>   - 感觉 IDXGIAdapter 约等于 /dev/dri/card0 ... 等加速设备
>   - 但也不是，因为 DRM 的 master 节点的访问限制 (?)
>   - TODO: 理一理 DRM
> - Buffer Object Management

-->

<h2 id="GameApp-Init"><a href="#GameApp-Init" class="headerlink" title="GameApp::Init()"></a><code>GameApp::Init()</code></h2><ul>
<li><code>D3DApp::Init()</code><ul>
<li><code>InitMainWindow()</code><ul>
<li><code>RegisterClass(WNDCLASS *)</code>: 注册</li>
<li><code>AdjustWindowRect()</code></li>
<li><code>CreateWindow()</code></li>
<li><code>ShowWindow()</code></li>
<li><code>UpdateWindow()</code></li>
</ul>
</li>
<li><code>InitDirect3D()</code><ul>
<li><p><code>D3D11CreateDevice()</code>: 采用 11.1 的 Feature Level，不行则降级</p>
<p>该函数会返回 Immediate Context (<code>ID3D11DeviceContext</code>), 设备 (<code>ID3D11Device</code>) 和特性等级</p>
</li>
<li><p><code>ID3D11Device::CheckMultisampleQualityLevels</code>: 查询给定 DXGI_FORMAT 是否支持给定倍数的 MSAA</p>
</li>
<li><p>将前面的 <code>ID3D11Device</code> Cast 到 <code>IDXGIDevice</code></p>
<blockquote>
<p>An <code>IDXGIDevice</code> interface implements a derived class for DXGI objects that produce image data.</p>
</blockquote>
</li>
<li><p><code>IDXGIDevice::GetAdapter</code> 拿到 <code>IDXGIAdapter</code></p>
<blockquote>
<p>The <code>IDXGIAdapter</code> interface represents a display subsystem (including one or more GPUs, DACs and video memory).</p>
</blockquote>
</li>
<li><p><code>IDXGIAdapter::GetParent</code> 拿到 <code>IDXGIFactory1</code></p>
<blockquote>
<p>这里的 <code>GetParent</code> 是 <code>IDXGIAdapter</code> 作为 <code>IDXGIObject</code> 的方法，可以获得构造它的工厂类。</p>
<p>The <code>IDXGIFactory1</code> interface implements methods for generating DXGI objects.</p>
</blockquote>
</li>
<li><p>尝试将 <code>IDXGIFactory1</code> Cast 到 <code>IDXGIFactory2</code> (DXGI 1.2 新增)</p>
<ul>
<li>如果支持 DXGI 1.2，则用 <code>CreateSwapChainForHwnd</code> 来创建交换链</li>
<li>否则，用 <code>CreateSwapChain</code> 来创建交换链<blockquote>
<p>这两个函数都可以创建窗口 &#x2F; 全屏幕交换链；DXGI 1.2 增加了新的、到其它输出目标的交换链创建功能，所以这里进行了重构。</p>
<p>也要注意，不同 DirectX 可以支持的<a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/windows/win32/api/dxgi/ne-dxgi-dxgi_swap_effect">交换链的交换行为类型</a>是不同的。大体上，交换链的交换行为可以分为</p>
<ul>
<li>DISCARD vs SEQUENTIAL: 可以参考 <a target="_blank" rel="noopener" href="https://gamedev.stackexchange.com/questions/58654/what-is-the-difference-between-dxgi-swap-effect-discard-and-dxgi-swap-effect-seq">StackExchange</a>，区别就是一个驱动可以放心扔掉，另一个必须保留回读可能</li>
<li>FILP vs BLIT (Bit Block Transfer): 决定是用交换指针还是数据拷贝的方法来从交换链被 Present 的 Surface 中拿取数据</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p><code>IDXGIFactory1::MakeWindowAssociation</code> 来取消让 DXGI 接收 Alt-Enter 的键盘消息并且切换窗口和全屏模式</p>
</li>
<li><p><code>D3D11SetDebugObjectName()</code></p>
<ul>
<li><code>ID3D11DeviceChild::SetPrivateData(WKPDID_D3DDebugObjectName, ...)</code> 来设置资源的内部数据，这里是调试名称</li>
</ul>
</li>
<li><p><code>DXGISetDebugObjectName()</code></p>
<ul>
<li><code>IDXGIObject::SetPrivateData(WKPDID_D3DDebugObjectName, ...)</code> 来设置资源的内部数据，这里是调试名称</li>
</ul>
</li>
<li><p><code>OnResize()</code></p>
<ul>
<li><code>IDXGISwapChain::ResizeBuffers()</code></li>
<li><code>IDXGISwapChain::GetBuffer()</code> 拿到 <code>ID3D11Texture2D</code> 形式的 Back Buffer</li>
<li><code>IDXGISwapChain::CreateRenderTargetView()</code> 创建绑定到上面 Back Buffer 的 Texture 的渲染目标视图</li>
<li><code>D3D11SetDebugObjectName</code> 来设置 Back Buffer 的调试名称 </li>
<li><code>ID3D11Device::CreateTexture2D()</code> 来创建深度模板缓冲 (Depth Stencil Buffer)，类型 <code>ID3D11Texture2D</code>，包含大小，MipLevel，采样描述等</li>
<li><code>ID3D11Device::CreateDepthStencilView()</code> 来创建前面缓冲对应的深度模板视图</li>
<li><code>ID3D11DeviceContext::OMSetRenderTargets()</code> 来将渲染目标视图和深度木板视图绑定到管线</li>
<li><code>ID3D11DeviceConetxt::RSSetViewports()</code> 绑定 Viewport 信息到光栅器状态</li>
<li><code>D3D11SetDebugObjectName()</code> 设置调试前面各种视图对象的对象名</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><code>InitEffect()</code><ul>
<li><code>CreateShaderFromFile()</code>: 传入 CSO (Compiled Shader Object) 和 Shader 文件，输出 <code>ID3DBlob *</code><ul>
<li>如果有缓存，则用 <code>D3DReadFileToBlob</code> 装入，并返回</li>
<li><code>D3DCompileFromFile()</code>: 编译并生成 <code>ID3DBlob</code> 对象</li>
<li>如果指定了缓存路径，则 <code>D3DWriteBlobToFile()</code> 进行输出<blockquote>
<p>分别创建了 <code>vs_5_0</code> 和 <code>ps_5_0</code> Shader Model 的 Shader Blob</p>
</blockquote>
</li>
</ul>
</li>
<li><code>ID3D11Device::CreateVertexShader()</code>，根据 Shader Bytecode 创建 <code>ID3D11VertexShader</code> 对象<blockquote>
<p>注意这个函数支持传入 Class Linkage，这是一种在 Shader 间共享类型和变量的机制，在 Shader Model 5 被引入。更详细的用法可以参考 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/windows/win32/direct3dhlsl/overviews-direct3d-11-hlsl-dynamic-linking-class">Dynamic Linking Class | MSDN</a></p>
<p>TODO: 研究一下</p>
</blockquote>
</li>
<li><code>ID3D11Device::CreateInputLayout()</code> 传入输入元素描述符和 Shader，传出 <code>ID3D11InputLayout</code> 对象</li>
<li><code>ID3D11Device::CreatePixelShader()</code> ，根据 Shader Bytecode 创建 <code>ID3D11PixelShader</code> 对象</li>
</ul>
</li>
<li><code>InitResource()</code><ul>
<li><code>ID3D11Device::CreateBuffer()</code> 创建顶点缓冲区 (<code>ID3D11Buffer</code>) ，并传入初始化数据</li>
<li><code>ID3D11Device::CreateBuffer()</code> 创建索引缓冲区 (<code>ID3D11Buffer</code>) ，并传入初始化数据</li>
<li><code>ID3D11DeviceContext::IASetIndexBuffer()</code> 设置 Immediate Context 绑定索引缓冲区</li>
<li><code>ID3D11Device::CreateBuffer()</code> 创建常量缓冲区 (<code>ID3D11Buffer</code>) ，不是用初始化数据<ul>
<li>此处设置 <code>D3D11_BUFFER_DESC</code> 的 <code>CPUAccessFlags</code> 为 <code>D3D11_CPU_ACCESS_WRITE</code>，让 CPU 可以改变其值</li>
</ul>
</li>
<li><code>ID3D11DeviceContext::IASetVertexBuffers()</code> 设置顶点缓冲区，stride 和 offset</li>
<li><code>ID3D11DeviceContext::IASetPrimitiveTopology()</code> 设置图元类型</li>
<li><code>ID3D11DeviceContext::IASetInputLayout()</code> 设置输入布局</li>
<li><code>ID3D11DeviceContext::VSSetShader()</code> 绑定顶点着色器到管线</li>
<li><code>ID3D11DeviceContext::VSSetConstantBuffers()</code> 设置常量缓冲区<blockquote>
<p>这里当然是拿着 ID3D11Buffer 去设置</p>
</blockquote>
</li>
<li><code>ID3D11DeviceContext::PSSetShader()</code> 设置像素着色器</li>
<li><code>D3D11SetDebugObjectName()</code> 将 Input Layout, Shader 和 Buffer 设置好调试用名字</li>
</ul>
</li>
</ul>
<h2 id="GameApp-Run"><a href="#GameApp-Run" class="headerlink" title="GameApp::Run()"></a><code>GameApp::Run()</code></h2><blockquote>
<p>关于 Windows 消息机制的相关介绍可以参考 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/windows/win32/winmsg/about-messages-and-message-queues">About messages and message queues | MSDN</a>。</p>
</blockquote>
<p>运行首先依赖 Windows 窗口程序本身的主事件循环（<code>PeekMessage()</code> &#x3D;&gt; <code>TranslateMessage()</code> &#x3D;&gt; <code>DispatchMessage()</code>)。</p>
<p>主窗口的消息处理函数中，主要会处理：</p>
<ul>
<li><code>WM_SIZE</code>: 如果在 <code>WM_ENTERSIZEMOVE</code> 和 <code>WM_EXITSIZEMOVE</code> 中间，则忽略，否则调用 <code>OnResize()</code> 重新配置交换链并绑定到管线</li>
<li><code>WM_ACTIVATE</code>: 窗口不活跃时暂停渲染</li>
<li><code>WM_DESTROY</code>: 窗口退出消息</li>
</ul>
<p>如果没有待处理的窗口消息，则会进入：</p>
<ul>
<li><code>CalculateFrameStats()</code>: 根据定时器计算时长并更新窗口标题</li>
<li><code>UpdateScene()</code>: 更新场景 (主要是更新常量缓冲)<ul>
<li>计算更新后的常量缓冲区值</li>
<li><code>ID3D11DeviceContext::Map</code> 传入 Constant Buffer 对象<blockquote>
<p><a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/windows/win32/api/d3d11/nf-d3d11-id3d11devicecontext-map">MSDN</a>: Gets a pointer to the data contained in a subresource, and denies the GPU access to that subresource.</p>
<p>这里要指定映射类型 (CPU 可读，CPU 可写，CPU 可写且原内容可放弃)；不过，这里还有一种类型，叫做 <code>D3D11_MAP_WRITE_NO_OVERWRITE</code>，这块 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/windows/win32/api/d3d11/ne-d3d11-d3d11_map">MSDN 的文档</a>有比较详细的解释。</p>
<p>也可以看看<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/341476240">这篇</a>知乎专栏作为参考。</p>
</blockquote>
<!-- TODO: 调查一下这个问题 --></li>
<li><code>memcpy(mappedData.pData, &amp;cpuCBuffer, sizeof(cpuConstBuffer))</code> 将数据拷贝到 <code>D3D11_MAPPED_SUBRESOURCE::pData</code> 成员处</li>
<li><code>ID3D11DeviceContext::Unmap</code> 解除内存映射</li>
</ul>
</li>
<li><code>DrawScene()</code>: 绘制场景<ul>
<li><code>ID3D11DeviceContext::ClearRenderTargetView()</code>: 用给定颜色清空渲染目标视图</li>
<li><code>ID3D11DeviceContext::ClearDepthStencilView()</code>: 用给定深度和模板值清空深度模板视图</li>
<li><code>ID3D11DeviceContext::DrawIndexed()</code>: 绘制给定的立方体</li>
<li><code>IDXGISwapChain::Present(SyncInterval=0, flags=0)</code>: 告知交换链已经完成绘制，可以呈现，并且要求立即呈现<blockquote>
<p><a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/windows/win32/api/dxgi/nf-dxgi-idxgiswapchain-present">IDXGISwapChain::Present</a>: Presents a rendered image to the user.</p>
</blockquote>
</li>
</ul>
</li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
    -->
  </div>
  
</article>



    
      <article id="paper-reading-paper-reading/icarus-nerf" class="article article-type-paper-reading" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/paper-reading/icarus-nerf/"><strong>论文阅读 | ICARUS: NeRF 硬件加速器</strong></a>
      <small class=article-date-index>&nbsp; 2022-10-07</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/paper-reading/icarus-nerf/" class="article-date">
  <time datetime="2022-10-06T16:00:00.000Z" itemprop="datePublished">2022-10-07</time>
</a>-->
      <!--
-->
      <!--
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>本篇文章介绍了 NeRF 硬件加速的实现。</p>
<h2 id="NeRF-回顾"><a href="#NeRF-回顾" class="headerlink" title="NeRF 回顾"></a>NeRF 回顾</h2><img src="/paper-reading/icarus-nerf/nerf-overview.png" class="" title="NeRF Overview from Original Paper">

<p>Neural Radiance Field，简称 NeRF，最开始在 ECCV 2020 上<a target="_blank" rel="noopener" href="https://www.matthewtancik.com/nerf">被提出</a>，提出了以神经网络编码辐射场的一种技术，并且将其运用到了基于图片的场景重建等多个领域中，是近年来受关注度相当高的一篇工作。</p>
<p>NeRF 的网络部分输入为 5D: 位置 $ (x,y,z) $ 和朝向 $ (\theta, \phi) $，输出为该位置的 RGB 颜色和密度。</p>
<p>NeRF 在给定相机位置下最终渲染的输出用类似体渲染 (Volumetric Rendering) 的办法来实现。</p>
<h3 id="NeRF-体渲染"><a href="#NeRF-体渲染" class="headerlink" title="NeRF 体渲染"></a>NeRF 体渲染</h3><p>对给定的相机光线 $ {\bf r}(t) &#x3D; {\bf o} + t{\bf d} $ 来说，最终输出的颜色 $ {\bf C}(r) $ 以下式表示：</p>
$$
C({\bf r}) = \int_{t_n}^{t_f} T(t) \sigma({\bf r}(t)) {\bf c}({\bf r}(t), {\bf d}) dt 
$$

<p>其中：</p>
<ul>
<li>$ T(t) = \exp (-\int_{t_n}^{t} \sigma({\bf r}(s)) ds ) $ 为光线从 $ t_n $ 能打到 $ t $ 的概率<ul>
<li>比如说，如果射线穿过的部分密度都比较大，那 $ T(t) $ 就会比较小</li>
</ul>
</li>
<li>$ \sigma({\bf r}(t)) $ 是该 $ t $ 对应的点 $ {\bf r}(t) $ 的密度</li>
<li>$ {\bf c}({\bf r}(t), {\bf d}) $ 是网络给定方向和位置后输出的 RGB 颜色值</li>
<li>$ t_n $ 和 $ t_f $ 分别为射线进入和射出 NeRF 有效区域的包围盒时所对应的最近和最远参数值</li>
</ul>
<p>不过这个积分显然不能很容易的解析求解，NeRF 的做法是采用数值积分的那一套。</p>
<p>首先，利用分层抽样 (stratified sampling) 的技术，将 $ [t_n, t_f] $ 分成 $ N $ 个均匀的小区间，然后在每个小区间均匀采样出一个 $ t_i $ 出来。</p>
<p>然后，用下面的量 $ \hat C({\bf r}) $ 来估计上面的 $ C({\bf r}) $：</p>
$$
\hat C({\bf r}) = \sum_{i=1}^{N} T_i (1-\exp(-\sigma_i \delta_i)) {\bf c}_i
$$

<p>其中：</p>
<ul>
<li>$ T_i = \exp(- \sum_{j=1}^{i-1} \sigma_j \delta_j) $</li>
<li>$ \delta_i = t_{i+1} - t_i $ 为两临近采样点的距离</li>
</ul>
<blockquote>
<p>为什么会变成这个形式？可以参考 arXiv 上的 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2209.02417.pdf">Volume Rendering Digest (for NeRF)</a></p>
</blockquote>
<!-- 没看，TODO: 研究一下 -->

<p>原文中提到，从所有的 $ ({\bf c}_i, \delta_i) $ 对考虑的话，$ \hat C(r) $ 的计算显然是可微的，并且可以看成从最开始一直用 $ \alpha_i &#x3D; 1 - \exp(\sigma_i \delta_i) $ 的透明度往上面做 alpha blending。</p>
<!-- TODO: why alpha value like that -->

<h3 id="NeRF-网络"><a href="#NeRF-网络" class="headerlink" title="NeRF 网络"></a>NeRF 网络</h3><p>网络部分用位置编码 (Positional Encoding) + Coarse MLP + Fine MLP。</p>
<h4 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h4><p>位置编码用来改善网络对高频细节的学习效果。</p>
<p>位置编码层可以如下描述：</p>
$$
\gamma(p) = (\sin(2^0 \pi p), \cos(2^0 \pi p), ..., \sin(2^{L-1} \pi p), \cos(2^{L-1} \pi p))
$$

<h4 id="Coarse-amp-Fine-MLP"><a href="#Coarse-amp-Fine-MLP" class="headerlink" title="Coarse &amp; Fine MLP"></a>Coarse &amp; Fine MLP</h4><p>NeRF 同时使用两个 MLP 来表示场景，一个粗粒度 MLP 和一个细粒度 MLP。</p>
<p>渲染的时候，首先用分层抽样的办法，在粗粒度网络中用前面提到的体渲染方法进行渲染，并且得到输出 $ \hat C_c(r) $：</p>
$$
\hat C_c(r) = \sum_{i=1}^{N_c} w_i c_i, \quad w_i = T_i (1-\exp(\sigma_i \delta_i))
$$

<p>然后，计算归一化权重 $ \hat w_i &#x3D; w_i &#x2F; \sum_{i&#x3D;1}^{N_c} w_i $，并且用计算好的归一化权重作为概率分布函数 (cumulative distribution function)，再在这条直线上采样 $ N_f $ 个位置，将这 $ N_c + N_f $ 个位置送入细粒度 MLP 进行推理，再用前面的办法渲染得到最终的颜色值。</p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>采用简单的把 Coarse MLP 和 Fine MLP 与真实值之间的 $ L^2 $ 损失直接加起来的办法。</p>
<h2 id="ICARUS"><a href="#ICARUS" class="headerlink" title="ICARUS"></a>ICARUS</h2><img src="/paper-reading/icarus-nerf/icarus-overview.png" class="" title="ICARUS Overview">

<h3 id="NeRF-计算过程回顾"><a href="#NeRF-计算过程回顾" class="headerlink" title="NeRF 计算过程回顾"></a>NeRF 计算过程回顾</h3><ol>
<li>对像素所发出射线上的采样，得到点 $ ({\bf p}_1, …, {\bf p}_N) $</li>
<li>查询 MLP 网络：$ ({\bf p}_i, {\bf d}_i) \to ({\bf c_i}, \sigma_i) $</li>
<li>进行多次 alpha-blending</li>
</ol>
<h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><p>架构设计时主要有以下目标：</p>
<ol>
<li>“端到端” - 芯片输入位置和方向，输出像素颜色，减少片上片外数据交换的额外开销（计算时间、功耗）</li>
<li>使用定点数 - 有效降低浮点数运算开销</li>
<li>架构设计要一定灵活性，尽量兼容比较多的 NeRF 衍生网络</li>
</ol>
<h4 id="如何使用定点数？"><a href="#如何使用定点数？" class="headerlink" title="如何使用定点数？"></a>如何使用定点数？</h4><p>目前的实现是将在 GPU 上训练好的 NeRF 的权重进行量化 (quantization)，再导出。不过，目前也有一些工作在 quantization-aware training 方面，可能对这个网络的训练过程有所帮助。</p>
<h3 id="位置编码单元-PEU"><a href="#位置编码单元-PEU" class="headerlink" title="位置编码单元 (PEU)"></a>位置编码单元 (PEU)</h3><p>设计位置编码单元 (Positional Encoding Unit, PEU) 的目的是在 PEU 前和 PEU 后的向量维数增加了很多倍（对原 NeRF 来说位置是 20 倍，方向是 8 倍），如果在 ICARUS 内部进行计算的话，可以减少很大一部分外部存储传输，降低传输总用时。</p>
<p>PEU 部件主要在做这件事：</p>
$$
\phi(x; A) = [\cos A^T x, \sin A^T x]
$$

<p>其中 $ A $ 一般为一个行数比列数多的矩阵，用来升维。</p>
<p>PEU 单元对应的设计如下 (Fig. 4(b))：</p>
<img src="/paper-reading/icarus-nerf/peu-overview.png" class="" title="PEU Overview">

<p>可以看到，就是矩阵乘法单元和 CORDIC 单元的组合。</p>
<blockquote>
<p>一些关于矩阵乘和 CORDIC 单元的大概印象：<br>矩阵乘：有很多工作，比如搜索 Systolic array 等等</p>
<ul>
<li>不过我不清楚 SOTA 情况<br>CORDIC: <a target="_blank" rel="noopener" href="https://zipcpu.com/dsp/2017/08/30/cordic.html">https://zipcpu.com/dsp/2017/08/30/cordic.html</a></li>
<li>不过我也不清楚 SOTA 情况</li>
</ul>
</blockquote>
<p>具体设计上来说，ICARUS 支持对 dim&#x3D;3 和 dim&#x3D;6 的两种输入进行位置编码，并且扩展到 dim&#x3D;128。PEU 内部设计有两个 3x128 的内存块和 6 组 MAC (Multiply-ACcumulate) 单元，当计算 dim&#x3D;6 的输入时会全部启用，当计算 dim&#x3D;3 的输入时只启用一半。</p>
<h3 id="MLP-Engine"><a href="#MLP-Engine" class="headerlink" title="MLP Engine"></a>MLP Engine</h3><p>MLP 引擎主要进行 $ f(Wx+b) $ 类型的计算。</p>
<p>MLP 引擎包含有：</p>
<ul>
<li>一个 Multi-output Network block (MONB)，负责计算中间的隐藏层</li>
<li>一个 Single-output network block (SONB)，负责计算最后的输出层<ul>
<li>不继续用 MONB 的原因是，全连接的 MONB 比只输出一个数字的 SONB 面积要大得多</li>
</ul>
</li>
<li>两个 activation memory block</li>
</ul>
<p>对于 MLP 计算来说，实现是这样的：</p>
<img src="/paper-reading/icarus-nerf/mlp-compution-overview.png" class="" title="MLP Overview">

<p>首先，将 MLP 的权重拆成 64 x 64 的小块，方便硬件上的复用，并且同样的权重可以被多组输入向量复用，从而降低内存带宽开销，代价方面只需要暂存该 batch 内的中间结果就可以（这里选择 <code>batch_size=128</code>）。</p>
<p>每个 64 x 64 的矩阵-向量乘法再进行分片，变成按矩阵列分割的 64 个列向量 - 向量的内积乘法（即 $ [\alpha_1 … \alpha_{64}] [x_1 … x_{64}]^T $，每个 $ \alpha_i x_i $ 的部分和用一个 RMCM 模块实现：</p>
<img src="/paper-reading/icarus-nerf/working_principle_rmcm.png" class="" title="RMCM Principle">

<p>大概来说，是因为乘法可以变成移位加法：</p>
$$
3x = 1x << 1 + 1x
$$

<p>所以权重 load 进来的作用就是预先选择好路径上的移位和加法器，然后数据从这些器件中流过去就行。</p>
<p>另一个优化是高一半的移位和加法路径直接用上一次的值来替换，然后网络训练的时候也作此改动。这样可以节省 1&#x2F;3 的面积，同时输出基本没有视觉质量损失。</p>
<p>SONB 的架构基本上和 MONB 差不多，只是 RMCM 块用不到了，用普通的向量乘法块就可以了。</p>
<img src="/paper-reading/icarus-nerf/sonb-overview.png" class="" title="SONB Overview">

<h3 id="Volume-Rendering-Unit"><a href="#Volume-Rendering-Unit" class="headerlink" title="Volume Rendering Unit"></a>Volume Rendering Unit</h3><img src="/paper-reading/icarus-nerf/VRU-Overview.png" class="" title="VRU Overview">

<p>VRU 模块主要要负责下面的计算：</p>
<img src="/paper-reading/icarus-nerf/VRU-classic.png" class="" title="VRU Classic">

<p>这里，他处理成下面的形式：</p>
<img src="/paper-reading/icarus-nerf/VRU-rewrite.png" class="" title="VRU Rewrite">

<p>然后用上面的网络计算。</p>
<h3 id="原型验证"><a href="#原型验证" class="headerlink" title="原型验证"></a>原型验证</h3><img src="/paper-reading/icarus-nerf/FPGA-prototyping.png" class="">

<p>验证平台使用的是 Synopsys HAPS-80 S104，验证时使用的工艺是 40nm CMOS 工艺。</p>
<img src="/paper-reading/icarus-nerf/icarus-comparation.png" class="">

<!-- 
#### 调整到 Surface Light Field 任务

> TODO

-->
      
    </div>
	
    <!--
	
    -->
    <!--
    
    -->
  </div>
  
</article>



    
      <article id="paper-reading-paper-reading/pbr-feature-line" class="article article-type-paper-reading" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/paper-reading/pbr-feature-line/"><strong>论文阅读 | 基于物理的特征线渲染</strong></a>
      <small class=article-date-index>&nbsp; 2022-08-28</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/paper-reading/pbr-feature-line/" class="article-date">
  <time datetime="2022-08-27T16:00:00.000Z" itemprop="datePublished">2022-08-28</time>
</a>-->
      <!--
-->
      <!--
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>本篇文章介绍了基于物理的特征线渲染方法。</p>
<p>特征线渲染是一种非真实感渲染技术，常常被用在剪影、产品效果图等一些需要特殊的艺术效果的场合。</p>
<p>本篇文章提出的，基于路径方法的特征线渲染方法，是基于如下的两方面观察：</p>
<ol>
<li>从路径的角度出发，现有的特征线渲染方法将特征线处理成了光源</li>
<li>特征线相交测试可以对任意的边开展，而不仅仅是在屏幕空间中</li>
</ol>
<p>基于上面的观察，本文提出的方法</p>
<ol>
<li>对一整个路径中每条路径段分别进行和特征线的相交测试</li>
<li>将交到的特征线视为吸收所有入射光，然后辐射用户自定义颜色的光源</li>
</ol>
<blockquote>
<p>TL;DR: 用 Path Tracing 做描边，把要描的边处理成光源，让描边也有景深、色散和反射等效果。</p>
</blockquote>
<h2 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h2><p>算法的基本架构很简单。</p>
<p>从传统的 Path Tracer 出发：</p>
<ol>
<li>对每个 path segment 依次进行和特征线的相交判断，并且</li>
<li>如果相交，则将特征线视为理想光源，并不再追下面的光源</li>
</ol>
<h3 id="相交判断"><a href="#相交判断" class="headerlink" title="相交判断"></a>相交判断</h3><p>从该 path segment 出发，以固定扩张率和当前路径总长度做一锥体，寻找锥体中的特征线。</p>
<p>实现上，本文采用从锥体较窄的一端发射查询射线，并且判断交点是否为特征线上的点的方法来进行判断，可能和 cone tracing 比较相似。</p>
<img src="/paper-reading/pbr-feature-line/cone-intersection-test.png" class="" title="cone-intersection-test">

<h3 id="采样权重修改"><a href="#采样权重修改" class="headerlink" title="采样权重修改"></a>采样权重修改</h3><p>前面提到，“如果相交，则将特征线视为理想光源，并不再追下面的光源”。本文中会将这种情况整条采样路径每个点的 pdf 值处理成和打到刚好有光源位于这里的情况完全一致。</p>
<p>不过，这样会让整个估计变成有偏估计，因为还存在有特征线（i.e. 有光源）但是没有采样到的情况，这种情况使用正常 pdf 会让最后相机处接收的 Irradiance 期望偏小，也就是特征线会比无偏的情况更不明显。</p>
<p>比较幸运的是，通过加密相交判断中发射的查询射线的数量，可以渐进的趋于无偏的情况。</p>
<img src="/paper-reading/pbr-feature-line/progressively-unbias.png" class="" title="progressively-unbias">

<h3 id="特征线判据"><a href="#特征线判据" class="headerlink" title="特征线判据"></a>特征线判据</h3><p>特征线的判断通过锥体中采样到的点和本 path segment 的起点和终点联合进行判断，主要有 MeshID, Albedo, Normal 和 Depth 四个方面的判据。</p>
<img src="/paper-reading/pbr-feature-line/feature-line-condition.png" class="" title="feature-line-condition">

<blockquote>
<p>其中 $ t_{\text{depth}} $ 文中提到有一个较为启发的设置方法。</p>
</blockquote>
<p>各项的效果如图所示：</p>
<img src="/paper-reading/pbr-feature-line/feature-line-condition-breakdown.png" class="" title="feature-line-condition-breakdown">

<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p>可以参考本文 Teaser：</p>
<img src="/paper-reading/pbr-feature-line/teaser.png" class="" title="teaser">

<p>可以看到，本文渲染的特征线有色散、景深模糊、反射等基于物理的效果。</p>
<h2 id="未来的工作"><a href="#未来的工作" class="headerlink" title="未来的工作"></a>未来的工作</h2><p>文章最后主要提及了如下的 Future Work：</p>
<ul>
<li>其它路径采样方法 (i.e. BDPT)</li>
<li>特征线锥形区域估计改进</li>
<li>特征线区域缓存</li>
<li>特征线模型改进<ul>
<li>反射 &#x2F; 半透特征线模型等</li>
</ul>
</li>
<li>将 lens blur 和色散效果集成到 <a target="_blank" rel="noopener" href="https://pixl.cs.princeton.edu/pubs/Cole_2006_DGI/index.php">Stylized Focus</a><ul>
<li>Stylized Focus 主要通过多个光栅化 pass 的叠加来实现风格化的景深和聚焦效果</li>
</ul>
</li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
    -->
  </div>
  
</article>



    
      <article id="post-towards-math-markdown" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/towards-math-markdown/"><strong>让 Hexo 支持内联 LaTeX 数学公式的 Markdown</strong></a>
      <small class=article-date-index>&nbsp; 2022-08-26</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/towards-math-markdown/" class="article-date">
  <time datetime="2022-08-25T16:00:00.000Z" itemprop="datePublished">2022-08-26</time>
</a>-->
      <!--
-->
      <!--
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <p>经过一周多陆陆续续的折腾，到<a target="_blank" rel="noopener" href="https://github.com/libreliu/libreliu.github.io/commit/627caa945440bed93a3fe69a90a932a84f7dceb0">现在</a>本博客基本实现了博客 Markdown 渲染和 Typora, VSCode 等的默认预览中数学公式的表现一致。</p>
<blockquote>
<p>Note: 大于号（<code>&gt;</code>）小于号（<code>&lt;</code>）目前没有做额外的转义（它们本身是 HTML 标签的结束和开始），但是这个用 <code>\lt</code> 和 <code>\gt</code> 就行了，所以有点懒得改。</p>
<p>如果要改的话，就对 <code>math</code> 的处理加上这两个东西的 escape 就好，MathJaX 本身会识别出 <code>&amp;lt;</code> 和 <code>&amp;gt;</code> 的。</p>
</blockquote>
<p>简单来说，我分别魔改了 <a target="_blank" rel="noopener" href="https://github.com/libreliu/marked">marked</a> 和 <a target="_blank" rel="noopener" href="https://github.com/libreliu/hexo-renderer-marked-math">hexo-renderer-marked</a> 两个包，实现了内联 LaTeX 的正确 Tokenize 和 Renderer (i.e. 什么也不做，原样输出)，再由浏览器里运行的 <a target="_blank" rel="noopener" href="https://github.com/libreliu/libreliu.github.io/commit/9523cf2ec2de2888fee50f2e9925313f96da5a35">MathJaX 3</a> 来进行 LaTeX 渲染。</p>
<p>魔改后的版本支持块公式 (block math) <code>$$ ... $$</code> 和内联公式 (inline math) <code>$ ... $</code>，并且内联公式内部的 <code>_</code> 不会和 Markdown 对 <code>_</code> 的使用冲突。</p>
<p>下面是渲染 Maxwell 方程组的示例：</p>
$$
\begin{aligned}
\nabla \cdot \mathbf{E} &= \frac {\rho} {\varepsilon_0} \\
\nabla \cdot \mathbf{B} &= 0 \\
\nabla \times \mathbf{E} &= -\frac{\partial \mathbf{B}} {\partial t} \\
\nabla \times \mathbf{B} &= \mu_0\left(\mathbf{J} + \varepsilon_0 \frac{\partial \mathbf{E}} {\partial t} \right) 
\end{aligned}
$$

<p>上面的 $ \mathbf{E} $ 是电场强度，$ \mathbf{B} $ 是磁感应强度，$ \mu_0$ 是真空磁导率，$ \epsilon_0 $ 是真空介电系数。</p>
<blockquote>
<p><code>marked</code> 是 <code>hexo-renderer-marked</code> 使用的 Markdown 渲染器，它负责把 Markdown 渲染成 HTML。</p>
</blockquote>
<h2 id="为什么要新造一个轮子？"><a href="#为什么要新造一个轮子？" class="headerlink" title="为什么要新造一个轮子？"></a>为什么要新造一个轮子？</h2><p>Google 一圈，现在有的 Hexo 内联 LaTeX 的方案都不是很让人满意：</p>
<ol>
<li><code>hexo-renderer-kramed</code> 使用的 <code>kramed</code> 从 2016 年开始已经没有再更新了</li>
<li><code>marked</code> 表示不会加入对 <code>$ ... $</code> 和 <code>$$ ... $$</code> 的支持 (<a target="_blank" rel="noopener" href="https://github.com/markedjs/marked/issues/722">markedjs&#x2F;marked, Issue #722</a>)</li>
<li><code>hexo-renderer-pandoc</code> 需要用户自己安装 <code>pandoc</code>，<code>pandoc</code> 本身很庞大，并且是 Haskell 编写，本文作者表示改不动；另外，直接 out-of-box 的装上之后，块公式 <code>pandoc</code> 总是会多生成 <code>\[ ... \]</code> 的 pair，决定弃坑</li>
<li>网络上还存在一些 patch 方案，比如<a target="_blank" rel="noopener" href="https://alexsixdegrees.github.io/2017/03/11/letaxinmarkdown/">这里</a>，直接把 <code>marked</code> 的 inline rule 改掉，让其不再将 <code>_</code> 作为合法的强调标志（比如 <code>_asdf_</code> 之类就不会渲染成 <em>asdf</em> 了）</li>
<li>其实也可以 <em>摆大烂</em>，把所有 LaTeX 和 Markdown 冲突的关键字都用反斜杠转义掉</li>
</ol>
<p>可以看到都不是太优雅。</p>
<h2 id="改动简介"><a href="#改动简介" class="headerlink" title="改动简介"></a>改动简介</h2><blockquote>
<p>其实一开始想给 <code>hexo-renderer-marked</code> 写插件，但是它只支持 extend <code>Tokenizer</code> 和 <code>Renderer</code>，把那些乱七八糟规则再写一遍又很难维护，所以最后放弃了这个想法。</p>
</blockquote>
<p>主要是对 <code>marked</code> 进行改动，让其支持 <code>$$ .. $$</code> 和 <code>$ .. $</code> 的 Tokenize，并且能无转义的输出。</p>
<p><code>marked</code> 采用正则表达式不断匹配的方式进行词法分析，对于部分块对象会继续进行行内的词法分析。词法分析后的 Toekn 流会送到 Renderer 进行输出。</p>
<p>详细可以看 <a target="_blank" rel="noopener" href="https://github.com/libreliu/marked">libreliu&#x2F;marked</a> 上面的提交。</p>
<p>由于人比较懒，没有在 npm 上加自己的包，而是直接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install github:libreliu/hexo-renderer-marked-math#master --save</span><br></pre></td></tr></table></figure>

<p>这个的缺点是每次 <code>npm update hexo-renderer-marked-math</code> 都要重新拉，并且版本管理上不是很友好。不过只是自己用的话其实无所谓。</p>
<h2 id="（作为菜鸡）踩过的坑"><a href="#（作为菜鸡）踩过的坑" class="headerlink" title="（作为菜鸡）踩过的坑"></a>（作为菜鸡）踩过的坑</h2><ol>
<li><p>NodeJS 的 <code>require</code> 在找不到 <code>index.js</code> 时，会去 <code>package.json</code> 中查找 <code>main</code> 字段，并且加载对应的模块。</p>
<p>可以注意到，<code>marked</code> 的 <code>main</code> 是 <code>./lib/marked.cjs</code>，这个文件需要运行 <code>npm run build</code> 生成。</p>
</li>
<li><p>调试 Promise 链可以采用 Bluebird 的<a target="_blank" rel="noopener" href="http://bluebirdjs.com/docs/api/promise.longstacktraces.html">Promise.longStackTraces()</a>。</p>
</li>
</ol>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><a target="_blank" rel="noopener" href="https://gist.github.com/3846masa/cde99a18a8d7ad225cf7">这里</a>在 2015 年对 VSCode 的 Markdown 渲染的 patch 对本更改有参考意义。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/zq1997/math-marked">math-marked</a>这个项目在我基本写完之后才看到，不过作者没有基于原来的 commit 继续改，后续升版本会比较费劲。</p>

      
    </div>
	
    <!--
	
    -->
    <!--
    
    -->
  </div>
  
</article>



    
      <article id="paper-reading-paper-reading/slang-shader-framework" class="article article-type-paper-reading" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/paper-reading/slang-shader-framework/"><strong>论文阅读 | Slang</strong></a>
      <small class=article-date-index>&nbsp; 2022-07-31</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/paper-reading/slang-shader-framework/" class="article-date">
  <time datetime="2022-07-30T16:00:00.000Z" itemprop="datePublished">2022-07-31</time>
</a>-->
      <!--
-->
      <!--
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Slang 是在 HLSL 之上扩展的着色器语言，其旨在保证<strong>没有额外性能损失</strong>的情况下，解决现代游戏引擎和实时渲染应用中出现的，不同光源 &#x2F; 材质组合出现的 Shader 代码膨胀、晦涩难懂的基于宏的复用等问题。</p>
<p>Slang 针对原 HLSL，主要增加了以下的新特性：</p>
<ol>
<li>带可选成员类型约束的接口系统 (Interfaces)<ul>
<li>以及 <code>extension</code> 关键字来覆盖接口系统的默认行为，提供最大灵活性</li>
</ul>
</li>
<li>泛型系统 (Generics)</li>
<li>显式参数块 (Explicit Parameter Blocks)</li>
<li>Slang 编译器和提供运行时类型特化支持的编译器运行时 API</li>
<li>(论文发表后新增) 语法糖和其它易用性改进<ul>
<li>类 C# 的 getter&#x2F;setter 语法糖</li>
<li>运算符重载</li>
<li>模块系统</li>
</ul>
</li>
<li>(论文发表后新增) CUDA, OptiX 等非传统 Shader 编译目标</li>
</ol>
<p>从上面可以看出，Slang 自论文发布后还存在有功能演进，说明作为 Shader 语言本身还是有一定生命力的。</p>
<p>截至 2022 年 7 月 31 日，<a target="_blank" rel="noopener" href="https://github.com/shader-slang/slang">Slang 的 GitHub 仓库</a> 共有 978 个 Star，235 Open Issue 和 284 Closed Issue，最后一次提交在两天前，证明项目还是比较活跃的。</p>
<blockquote>
<p>Note: 据我浅薄的了解，HLSL 也在不断迭代新的功能，如 <a target="_blank" rel="noopener" href="https://devblogs.microsoft.com/directx/announcing-hlsl-2021/">HLSL 2021</a> 的 <code>template</code> 泛型支持等。<del>不过 GLSL 好像没啥大动作</del>(?)</p>
</blockquote>
<h2 id="Slang-语言特性介绍"><a href="#Slang-语言特性介绍" class="headerlink" title="Slang 语言特性介绍"></a>Slang 语言特性介绍</h2><h3 id="接口系统-Interfaces"><a href="#接口系统-Interfaces" class="headerlink" title="接口系统 (Interfaces)"></a>接口系统 (Interfaces)</h3><p>Slang 的接口表示一种约定，比如约定里面会有某种特定函数原型的函数实现，某种特定的成员结构体等，与 “traits” 的语言概念比较接近。</p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// define a interface</span></span><br><span class="line"><span class="keyword">interface</span> <span class="title">IFoo</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="function"><span class="built_in">int</span> <span class="title">myMethod</span>(<span class="params"><span class="built_in">float</span> arg</span>)</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// declare that MyType have conformance to interface IFoo</span></span><br><span class="line"><span class="keyword">struct</span> MyType : IFoo</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function"><span class="built_in">int</span> <span class="title">myMethod</span>(<span class="params"><span class="built_in">float</span> arg</span>)</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="built_in">int</span>)arg + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="泛型系统-Generics"><a href="#泛型系统-Generics" class="headerlink" title="泛型系统 (Generics)"></a>泛型系统 (Generics)</h3><p>泛型系统可以实现同时支持不同类型实例的函数。特别的，可以约束传入的形参类型为实现某种接口的类型，如下面的 <code>myGenericMethod</code> 约束 <code>T</code> 为实现 <code>IFoo</code> 接口的类型。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// define</span></span><br><span class="line"><span class="type">int</span> myGenericMethod&lt;T: IFoo&gt;(T arg)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> arg.myMethod(<span class="number">1.0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// invoke</span></span><br><span class="line">MyType obj;</span><br><span class="line"><span class="type">int</span> a = myGenericMethod&lt;MyType&gt;(obj); <span class="comment">// OK, explicit type argument</span></span><br><span class="line"><span class="type">int</span> b = myGenericMethod(obj); <span class="comment">// OK, automatic type deduction</span></span><br></pre></td></tr></table></figure>

<p>同时，Slang 还支持类似 C++ 的非类型模板形参的泛型参数输入，比如下面的 <code>N</code>：</p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> Array&lt;T, <span class="keyword">let</span> N : <span class="built_in">int</span>&gt;</span><br><span class="line">&#123;</span><br><span class="line">    T arrayContent[N];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>函数，<code>struct</code> 等语言组件都支持泛型。</p>
<blockquote>
<p>Note: HLSL 本身就支持作为 struct 的 arg 拥有成员函数。</p>
</blockquote>
<h3 id="显式参数块-Explicit-Parameter-Blocks"><a href="#显式参数块-Explicit-Parameter-Blocks" class="headerlink" title="显式参数块 (Explicit Parameter Blocks)"></a>显式参数块 (Explicit Parameter Blocks)</h3><blockquote>
<p>这个特性在 Slang 官方的语言文档中没有着重强调，主要是在 Slang 的这篇论文中强调了。</p>
</blockquote>
<p>现代图形 API（D3D12, Vulkan）对于 Shader 的输入参数是以 “parameter block” 的形式来组织的（例：Vulkan 中术语为 Descriptor Set），一个 Shader 的输入可以由多个 Descriptor Set 组成。</p>
<p>考虑到场景的绘制过程中，有一部分 Shader 参数是不变的（比如同一个绘制到主 RenderTarget 的 Pass 中摄像机的位置），那么把这些不变的参数单独拿出来组织成一个 Parameter Block，把剩下的一些变化频率不太一致的另一些参数（比如模型的 <code>modelMatrix</code>）拿出来作为一个或多个 Parameter Block 的话，就可以降低一部分绘制时的开销。</p>
<p>但是手工组织 Shader 的 layout（特别是对于不同的材质，我们有不同的 Shader 要用）是比较繁琐的，Slang 则对这个 Parameter Binding 和 Parameter Block 有专门的设计（<code>Shader Parameters</code>），可以方便的自动推导符合程序员设计要求的 layout 和 block。</p>
<h3 id="编译器和运行时-API"><a href="#编译器和运行时-API" class="headerlink" title="编译器和运行时 API"></a>编译器和运行时 API</h3><p>Slang 提供了功能丰富的运行时 API，其功能经过一些演进和论文中描述的也不是特别一致了。</p>
<p>Slang 的运行时 API 大概提供了如下机制：</p>
<ol>
<li>运行时 Shader 编译和特化 API<ul>
<li>比如，运行时要对新的材质类型重新编译 Shader，就可以使用这些 API</li>
</ul>
</li>
<li>反射机制<ul>
<li>可以获得某段 Slang Shader 中的函数、Shader 入口参数等信息</li>
</ul>
</li>
</ol>
<h3 id="语法糖"><a href="#语法糖" class="headerlink" title="语法糖"></a>语法糖</h3><p>Slang 的文档中描述了不少 Slang 的语法糖和易用性改进。</p>
<h4 id="类似-C-的-getter-x2F-setter-语法糖"><a href="#类似-C-的-getter-x2F-setter-语法糖" class="headerlink" title="类似 C# 的 getter &#x2F; setter 语法糖"></a>类似 C# 的 getter &#x2F; setter 语法糖</h4><figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> MyType</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">uint</span> flag;</span><br><span class="line"></span><br><span class="line">    property <span class="built_in">uint</span> highBits</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">get</span> &#123; <span class="keyword">return</span> flag &gt;&gt; <span class="number">16</span>; &#125;</span><br><span class="line">        <span class="keyword">set</span> &#123; flag = (flag &amp; <span class="number">0xFF</span>) + (newValue &lt;&lt; <span class="number">16</span>); &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="基于全局函数的运算符重载"><a href="#基于全局函数的运算符重载" class="headerlink" title="基于全局函数的运算符重载"></a>基于<strong>全局函数</strong>的运算符重载</h4><blockquote>
<p>HLSL 2021 支持了基于<strong>成员函数</strong>的运算符重载：[Announcing HLSL 2021</p>
<ul>
<li>DirectX Developer Blog](<a target="_blank" rel="noopener" href="https://devblogs.microsoft.com/directx/announcing-hlsl-2021/">https://devblogs.microsoft.com/directx/announcing-hlsl-2021/</a>)</li>
</ul>
<p>而 GLSL 截至 2022 年 7 月 31 日还在咕咕：<a target="_blank" rel="noopener" href="https://github.com/KhronosGroup/GLSL/issues/107">Operator overloading · Issue #107 · KhronosGroup&#x2F;GLSL</a></p>
</blockquote>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> MyType</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">int</span> val;</span><br><span class="line">    __init(<span class="built_in">int</span> x) &#123; val = x; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">MyType <span class="keyword">operator</span>+(MyType a, MyType b)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> MyType(a.val + b.val);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">int</span> <span class="title">test</span>()</span></span><br><span class="line">&#123;</span><br><span class="line">    MyType rs = MyType(<span class="number">1</span>) + MyType(<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">return</span> rs.val; <span class="comment">// returns 3.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="模块机制"><a href="#模块机制" class="headerlink" title="模块机制"></a>模块机制</h4><p>Slang 支持一个简单的模块机制，可以把要 import 的目标模块（就是一个 .slang 的 Slang Shader）中的定义导入当前单元。如果该模块此时再被其它模块 import 的话，这些被导入的模块是不会导入到它的“上一层”的单元中的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MyShader.slang</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 正常的导入</span></span><br><span class="line"><span class="keyword">import</span> YourLibrary;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 当然，也可以导入时覆盖前面描述的行为</span></span><br><span class="line">__export <span class="keyword">import</span> SomeOtherModule;</span><br></pre></td></tr></table></figure>

<h2 id="重构-Falcor-渲染器"><a href="#重构-Falcor-渲染器" class="headerlink" title="重构 Falcor 渲染器"></a>重构 Falcor 渲染器</h2><p>Falcor 是一个基于 D3D12 的实时渲染器。</p>
<blockquote>
<p>根据 README，Vulkan 实验性支持在进行中。</p>
</blockquote>
<p>作者从 Falcor 的 2.0.2 版本出发，重构了 5400 行着色器代码。</p>
<p>改进主要集中在如下方面：</p>
<ol>
<li><p>将一个大的 Parameter Block 拆分成 per-material 的 block</p>
</li>
<li><p>Falcor 原来的 Material 采用层次化的设计，每一层 (e.g. GGX, Lambertian, Phong) 都和下一层进行 blend，而渲染时，根据不同的 material 要 dispatch 不同的 shader 时，采用了很多 <code>#define</code> 和基于文本的 Shader Varient Cache 的查询环节。</p>
<p>作者重构时将这套系统用 Slang 的泛型系统重构，并且将标准材质的 Varient 用非类型形参编码成了若干个 int，进而加快了查询速度。</p>
</li>
<li><p>针对与 Material 类似的技术，实现了光源上的特化，在场景中只有某种类型光源的时候采用静态特化好的 Shader 变体，减少运行时判断的开销</p>
</li>
</ol>
<h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>通过重构 Falcor 渲染器，在 NVIDIA 的 ORCA 场景上的测试表明</p>
<ul>
<li>每帧 CPU 执行时间降低了 30%</li>
<li>光源和材料特化改进对部分场景的 GPU 时间有加速作用</li>
</ul>
<h3 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h3><p>作者分别在重构前和重构后的 Falcor 上实现了（基于 LTC 方法的）多边形面光源，</p>
<ul>
<li>重构前：需要改动 7 处，4 个文件，246 行</li>
<li>重构前，但加入光源分离机制：需要改动 8 处，5 个文件，253 行</li>
<li>重构后：只需要改动 1 处，1 个文件，249 行</li>
</ul>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><blockquote>
<p>We believe that all real-time graphics programmers could benefit from<br>a new generation of shader compilation tools informed by these<br>ideas. —— <em>Slang: language mechanisms for extensible real-time shading systems</em></p>
</blockquote>

      
    </div>
	
    <!--
	
    -->
    <!--
    
    -->
  </div>
  
</article>



    
      <article id="paper-reading-paper-reading/ddgi" class="article article-type-paper-reading" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <myh11 itemprop="name">
      <a class="article-title-index" href="/paper-reading/ddgi/"><strong>论文阅读 | Dynamic Diffuse Global Illumination with Ray-Traced Irradiance Fields</strong></a>
      <small class=article-date-index>&nbsp; 2022-07-23</small>
      <!--<a>
      <div = post.date  </div>
      </a>-->
      <br>
      <br> <!-- blair add -->
    </myh11>
  


      </header>
    
    <div class="article-meta">
      <!--<a href="/paper-reading/ddgi/" class="article-date">
  <time datetime="2022-07-22T16:00:00.000Z" itemprop="datePublished">2022-07-23</time>
</a>-->
      <!--
-->
      <!--
      
      -->
    </div>
	
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>本篇文章提供了一种高效的计算动态物体和动态光源情形下的全局光照的方法。</p>
<h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><h3 id="DDGI-light-probe"><a href="#DDGI-light-probe" class="headerlink" title="DDGI light probe"></a>DDGI light probe</h3><p>DDGI 是一种利用 light probe（光照探针）进行动态全局光计算的方法。</p>
<p>对于位于 $\mathrm{x’}$ 位置的 light probe，所有的出射方向可以视为从 probe 所在位置到以 probe 所在位置为中心的单位球面上点构成的向量的集合。此时，构造一个 $S^2 \to R^2$ 的映射，使得球面的八个扇区分别映射到八面体的八个面上，这个映射被称为八面体映射 (octahedron mapping)。</p>
<blockquote>
<p>文章中描述到，八面体映射的好处，在于可以将球面以比较均匀的参数化映射到正方形上去，方便之后将每个方向相对应的量储存到 2D 纹理上面去。</p>
</blockquote>
<p>通过八面体映射，就可以将 probe 每个方向的信息存储在正方形的纹理贴图上了。</p>
<p>不过，在这篇文章中，出于性能考虑，作者采用了类似 Variance Shadow Mapping 的方法，极大压缩了纹理贴图的分辨率，同时对于每个 probe 的贴图的每个方向，分别存放</p>
<ol>
<li>$E_i(\mathrm{x'}, w)$: probe 以 $\omega$ 方向为天顶的半球的入射 irradiance</li>
<li>$r(\omega)$: probe 在 $\omega$ 方向对应的最近邻图元的距离在半球面的均值<ul>
<li>也就是 $\int d(x’, \omega) d \omega$，其中 $d(x, \omega): R^3 \times \Omega \to R$ 为在 $x$ 处沿 $\omega$ 方向到最近邻图元的距离</li>
</ul>
</li>
<li>$r^2(\omega)$: probe 在 $\omega$ 方向对应的最近邻图元的距离的平方在半球面的均值</li>
</ol>
<p>三组信息。</p>
<blockquote>
<p>Recall: radiance 和 irradiance</p>
<ul>
<li>Radiance (辐射率): 单位面积单位立体角辐射功率，$ d\Phi &#x2F; (dS d\Omega) $</li>
<li>Irradiance (辐照度): 单位面积辐射功率 $ d\Phi &#x2F; dS $</li>
</ul>
</blockquote>
<h3 id="利用-probe-进行间接光计算"><a href="#利用-probe-进行间接光计算" class="headerlink" title="利用 probe 进行间接光计算"></a>利用 probe 进行间接光计算</h3><p>前面提到 probe 中存储的信息为 probe 所在位置中各个方向的入射 irradiance。如果把场景中各处的 irradiance 看成一个 irradiance 场，那么现在要处理的问题就是给定场在某些位置的值，插值出其他位置的值的过程。</p>
<p>对于漫反射，只需要关心入射 irradiance 而不需要具体的 radiance，所以只需要待着色图元的全局光入射 irradiance 信息。</p>
<p>irradiance 场大概可以这样描述：$R^3 \times S^2 \to Spectrum$</p>
<p>输入是 (位置, 方向)，输出是 Spectrum (e.g. RGBSpectrum)</p>
<p>可以想象到，如果场本身的变化相对于 probe 间距离来说变化比较缓慢，那么方法就会工作的比较好。</p>
<p>不过，也有一些会导致变化较快的情况：</p>
<ol>
<li>图元本身与 probe 所成夹角</li>
<li>图元被某些物体遮挡</li>
</ol>
<p>所以，DDGI 提出了这样的框架来进行着色：</p>
<figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// float3 n = shading normal, X = shading point, P = probe location</span></span><br><span class="line">float4 irradiance = float4(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">for</span> (each of <span class="number">8</span> probes around X) &#123;</span><br><span class="line">    float3 dir = P – X;</span><br><span class="line">    <span class="type">float</span> r = <span class="built_in">length</span>(dir);</span><br><span class="line">    dir *= <span class="number">1.0</span> / r;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// smooth backface</span></span><br><span class="line">    <span class="type">float</span> weight = (<span class="built_in">dot</span>(dir, n) + <span class="number">1</span>) * <span class="number">0.5</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// adjacency</span></span><br><span class="line">    weight *= trilinear(P, X);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// visibility (Chebyshev)</span></span><br><span class="line">    float2 temp = <span class="built_in">texelFetch</span>(depthTex, probeCoord).rg;</span><br><span class="line">    <span class="type">float</span> mean = temp.r, mean2 = temp.g;</span><br><span class="line">    <span class="keyword">if</span> (r &gt; mean) &#123;</span><br><span class="line">        <span class="type">float</span> variance = <span class="built_in">abs</span>(square(mean) – mean2);</span><br><span class="line">        weight *= variance / (variance + square(r – mean));</span><br><span class="line">    &#125;</span><br><span class="line">    irradiance += <span class="built_in">sqrt</span>(<span class="built_in">texelFetch</span>(colorTex, probeCoord) * weight;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> square(irradiance.rgb * (<span class="number">1.0</span> / irradiance.a));</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>irradiance.a</code> 的作用是什么..？</p>
<p>很多权重我理解是为了视觉效果，应该和物理正确没什么太大关系…</p>
<p>这里的也不是最终的版本（还要加上 normal bias），slides 里面提供了更加魔改的版本，不知道 RTXGI 里面是不是有更进一步的魔改</p>
</blockquote>
<h4 id="Chebyshev-项分析"><a href="#Chebyshev-项分析" class="headerlink" title="Chebyshev 项分析"></a>Chebyshev 项分析</h4><p>Chebyshev 不等式 (one-tailed version)：</p>
$$
P(x > t) \le \frac{\sigma^2}{\sigma^2 + (t-\mu)^2}
$$

<blockquote>
<p>可以参考 GAMES202 中<a target="_blank" rel="noopener" href="https://sites.cs.ucsb.edu/~lingqi/teaching/resources/GAMES202_Lecture_04.pdf">关于 Variance Soft Shadow Mapping 的部分</a></p>
</blockquote>
<p>相当于小于平均值时认为没有遮挡，大于平均值时按 Chebyshev 不等式的上界来估算被遮挡概率。</p>
<blockquote>
<p>有没有更好的估计方法？为什么这样估计是最好的？</p>
</blockquote>
<h3 id="各个项效果对比"><a href="#各个项效果对比" class="headerlink" title="各个项效果对比"></a>各个项效果对比</h3><p>原论文中有各项的作用展示：</p>
<img src="/paper-reading/ddgi/ddgi_term_comparation.png" class="" title="DDGI Term Comparation">

<p>其中 classic irradiance probe 应该就是只有三线性插值的结果。</p>
<h3 id="动态更新-probe-信息"><a href="#动态更新-probe-信息" class="headerlink" title="动态更新 probe 信息"></a>动态更新 probe 信息</h3><p>每一帧，DDGI 会进行如下的操作：</p>
<ol>
<li>从 $m$ 个活跃 probe 中，每个 probe 发射 $n$ 条光线，然后存储 $n \times m$ 个交点处的表面元信息（位置，法线）到一个类似 G-buffer 的结构中<ul>
<li>发射光线时采用每帧不同的 pattern，最大限度避免锯齿<ul>
<li>作者采用 “stochastically-rotated Fibonacci spiral pattern”<blockquote>
<p>不过作者 2017 年的文章中并没有详细说明此处的具体实现，需要阅读作者的代码</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
<li>对表面元信息进行直接光和间接光计算<ul>
<li>直接光：<ul>
<li>点光源和方向光光源：利用该 G-buffer 进行普通的 deferred rendering + variance shadow mapping</li>
<li>面积光光源：使用下面间接光方法，第一跳时考虑面积光</li>
</ul>
</li>
<li>间接光：采用周围的 probe 信息进行计算<ul>
<li>和前面一节描述的方法一致</li>
</ul>
</li>
<li>(多跳)间接光：通过 3 中每次用 Moving Average 方法来更新，实现多跳的信息传播</li>
</ul>
</li>
<li>更新这 $m$ 个活跃 probe 对应的纹理贴图<ul>
<li>利用 alpha-blending, $\alpha$ 取 0.85 到 0.98</li>
<li><code>newIrradiance[texelDir] = lerp(oldIrradiance[texelDir], Sum(ProbeRays(max(0,texelDir · rayDir) ∗ rayRadiance)...), alpha)</code></li>
</ul>
</li>
</ol>
<blockquote>
<p>符号说明: <code>lerp(a, b, alpha) = a * alpha + b * (1-alpha)</code></p>
</blockquote>
<h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><ul>
<li><a target="_blank" rel="noopener" href="https://research.nvidia.com/sites/default/files/pubs/2017-02_Real-Time-Global-Illumination/light-field-probes-final.pdf">Real-Time Global Illumination using Precomputed Light Field Probes</a><ul>
<li>McGuire 这篇 2017 年的工作中关于 GI 的部分和这篇文章很像，只是当时他在 light probe 中存储比较高分辨率的最近邻图元到 probe 距离，并且用这个距离来进行基于 probe 阵列的 ray trace，而不是采用硬件 ray trace。</li>
<li>并且他在这篇工作中提到，可以采用将 BSDF 分解成 diffuse + glossy (所有不 diffuse 的项)，对 glossy 用其它方法来处理 (比如 raytrace + post filter) 来实现整个场景的 GI。</li>
</ul>
</li>
</ul>

      
    </div>
	
    <!--
	
    -->
    <!--
    
    -->
  </div>
  
</article>



    
      <nav id="page-nav">
        <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
      </nav>
    

</section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 Libre Liu&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a target="_blank" rel="noopener" href="http://github.com/52binge/hexo-theme-blairos">blairos</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX"],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true
    }
  });
</script>
<script>
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$']],
      processEscapes: true,
    },
    options: {
    renderActions: {
      findScript: [10, function (doc) {
        for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
          const display = !!node.type.match(/; *mode=display/);
          const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
          const text = document.createTextNode('');
          node.parentNode.replaceChild(text, node);
          math.start = {node: text, delim: '', n: 0};
          math.end = {node: text, delim: '', n: 0};
          doc.math.push(math);
        }
      }, '']
    }
  }
  };
</script>
<script type="text/javascript" id="MathJax-script" src="/js/mathjax/tex-chtml.js">
</script>

    

<script src="/js/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


  </div>
</body>
</html>
